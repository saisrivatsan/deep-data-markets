{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eeb1910-1d87-4b22-ab93-b757826befa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_printoptions(sci_mode = False, precision = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced48ba8-2805-4585-ab5b-ade9ada751bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "class HParams:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.num_states = 3\n",
    "        self.num_signals = 3\n",
    "        \n",
    "        # Minibatch size\n",
    "        self.batch_size = 2**15\n",
    "        self.num_menus = 1000\n",
    "\n",
    "        # Opt params\n",
    "        self.lr = 1e-3        \n",
    "        self.pi_temp = 0.2\n",
    "        self.u_temp = 0.005\n",
    "                \n",
    "        # Miscellaneous\n",
    "        self.seed = 0\n",
    "                  \n",
    "        self.max_iter = 20000 \n",
    "        self.print_iter = 1000\n",
    "        \n",
    "        self.device = \"cuda\"\n",
    "        \n",
    "        self.tst_num_batches = 1000\n",
    "                \n",
    "# Initialize config\n",
    "cfg = HParams()\n",
    "np.random.seed(cfg.seed)\n",
    "device = \"cuda\"\n",
    "\n",
    "# Utils\n",
    "def torch_var(x): return torch.tensor(x, device = cfg.device)\n",
    "def numpy_var(x): return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c0a8587-65ce-4d94-8a36-5e0de7af75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RochetNet(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(RochetNet, self).__init__()\n",
    "        self.num_menus = cfg.num_menus\n",
    "        self.num_states = cfg.num_states\n",
    "        self.num_signals = cfg.num_signals\n",
    "        self.device = cfg.device\n",
    "        \n",
    "        self.pi_temp_inv = torch.tensor(1.0/cfg.pi_temp).to(device)\n",
    "        self.u_temp_inv = torch.tensor(1.0/cfg.u_temp).to(device)\n",
    "        \n",
    "        #  Experiments and payments\n",
    "        self.pi = torch.empty((self.num_menus, self.num_states, self.num_signals), device = self.device, requires_grad = True)\n",
    "        self.pay = torch.empty((self.num_menus), device = self.device, requires_grad = True)\n",
    "        \n",
    "        # For IR constraints\n",
    "        self.pi_0 = torch.empty(1, self.num_states, self.num_signals).to(self.device)\n",
    "        self.pay_0 = torch.empty(1).to(self.device)\n",
    "        \n",
    "        # Initialization\n",
    "        self.reset_parameters()\n",
    "        \n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        \n",
    "        # Initialize pi and pay\n",
    "        nn.init.uniform_(self.pi.data, -1.0, 1.0)\n",
    "        nn.init.zeros_(self.pay.data)\n",
    "                \n",
    "        # Initialize IR menu\n",
    "        nn.init.ones_(self.pi_0.data)\n",
    "        nn.init.zeros_(self.pay_0.data)\n",
    "        self.make_responsive()\n",
    "        \n",
    "    def make_responsive(self):\n",
    "        \n",
    "        pi = numpy_var(self.pi)\n",
    "        for i in range(len(pi)):\n",
    "            _, col_ind = linear_sum_assignment(pi[i], True)\n",
    "            pi[i] = pi[i][:, col_ind]\n",
    "        self.pi = torch.tensor(pi, device = self.device, requires_grad = True)\n",
    "        \n",
    "    def delete_duplicates(self):\n",
    "        \n",
    "        pi_menu, pay_menu = self.get_menu()\n",
    "        pi_menu = numpy_var(pi_menu[:-1])\n",
    "        pay_menu = numpy_var(pay_menu[:-1])\n",
    "\n",
    "        # Sort by prices\n",
    "        pi_menu = np.round(pi_menu, 3)\n",
    "        sort_idx = np.argsort(pay_menu)\n",
    "        pi_menu, pay_menu = pi_menu[sort_idx], pay_menu[sort_idx]\n",
    "\n",
    "        # Select unique\n",
    "        _, unique_idx = np.unique(pi_menu, axis = 0, return_index = True)\n",
    "        pi, pay = numpy_var(self.pi), numpy_var(self.pay)\n",
    "        pi, pay = pi[unique_idx], pay[unique_idx]\n",
    "        prev_num_menus = self.num_menus\n",
    "        self.num_menus = len(unique_idx)\n",
    "        \n",
    "        self.pi = torch.tensor(pi, device = self.device, requires_grad = True)\n",
    "        self.pay = torch.tensor(pay, device = self.device, requires_grad = True)\n",
    "        print(\"Updated num_menus from %d --->: %d\"%(prev_num_menus, self.pi.shape[0]))\n",
    "        \n",
    "    def get_menu(self):\n",
    "        pi_menu = F.softmax(self.pi_temp_inv * torch.cat([self.pi, self.pi_0]), dim = -1)\n",
    "        pay_menu = torch.cat([self.pay, self.pay_0])\n",
    "        return pi_menu, pay_menu\n",
    "    \n",
    "    def forward(self, theta):\n",
    "        pi_menu, pay_menu = self.get_menu()\n",
    "        utility = torch.max(theta[:, None, :, None] * pi_menu, axis = -2)[0].sum(axis = -1) - pay_menu[None, :]\n",
    "        menu_idx = F.softmax( self.u_temp_inv * utility, dim = -1)\n",
    "        rev = menu_idx * pay_menu\n",
    "        return rev.sum(axis = -1)\n",
    "    \n",
    "    def compute_mechanism(self, theta):\n",
    "        pi_menu, pay_menu = self.get_menu()\n",
    "        utility = torch.max(theta[:, None, :, None] * pi_menu, axis = -2)[0].sum(axis = -1) - pay_menu[None, :]\n",
    "        menu_idx = torch.argmax(utility, axis = -1)\n",
    "        return pi_menu[menu_idx], pay_menu[menu_idx]\n",
    "        \n",
    "# Take care of u(theta) = \\max {theta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8022d2c6-6a28-48a9-915c-18810b75067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(batch_size):\n",
    "    T1 = np.random.dirichlet([1, 1, 4], batch_size)\n",
    "    T2 = np.random.dirichlet([1, 10, 1], batch_size)\n",
    "    mask = np.random.binomial(1, 0.5, size = (batch_size,1))\n",
    "    return mask * T1 + (1 - mask) * T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665f50ad-3eff-46b0-9734-1815d18003ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RochetNet(cfg).to(device)\n",
    "opt = torch.optim.RMSprop([net.pi, net.pay], lr = 1e-3)\n",
    "it = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3150ce20-e867-41e7-a356-ac9e9a9e2c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter: 1000], [Time Elapsed: 40.88s], [Revenue: 0.1233]\n",
      "Updated num_menus from 1000 --->: 933\n",
      "[Iter: 2000], [Time Elapsed: 78.75s], [Revenue: 0.1233]\n",
      "Updated num_menus from 933 --->: 874\n",
      "[Iter: 3000], [Time Elapsed: 114.60s], [Revenue: 0.1232]\n",
      "Updated num_menus from 874 --->: 818\n",
      "[Iter: 4000], [Time Elapsed: 148.15s], [Revenue: 0.1241]\n",
      "Updated num_menus from 818 --->: 765\n",
      "[Iter: 5000], [Time Elapsed: 179.19s], [Revenue: 0.1227]\n",
      "Updated num_menus from 765 --->: 715\n",
      "[Iter: 6000], [Time Elapsed: 208.26s], [Revenue: 0.1225]\n",
      "Updated num_menus from 715 --->: 669\n",
      "[Iter: 7000], [Time Elapsed: 235.52s], [Revenue: 0.1214]\n",
      "Updated num_menus from 669 --->: 626\n",
      "[Iter: 8000], [Time Elapsed: 261.25s], [Revenue: 0.1224]\n",
      "Updated num_menus from 626 --->: 586\n",
      "[Iter: 9000], [Time Elapsed: 285.44s], [Revenue: 0.1219]\n",
      "Updated num_menus from 586 --->: 551\n",
      "[Iter: 10000], [Time Elapsed: 308.06s], [Revenue: 0.1217]\n",
      "Updated num_menus from 551 --->: 519\n",
      "[Iter: 11000], [Time Elapsed: 329.32s], [Revenue: 0.1213]\n",
      "Updated num_menus from 519 --->: 489\n",
      "[Iter: 12000], [Time Elapsed: 349.20s], [Revenue: 0.1209]\n",
      "Updated num_menus from 489 --->: 461\n",
      "[Iter: 13000], [Time Elapsed: 368.04s], [Revenue: 0.1207]\n",
      "Updated num_menus from 461 --->: 436\n",
      "[Iter: 14000], [Time Elapsed: 386.12s], [Revenue: 0.1207]\n",
      "Updated num_menus from 436 --->: 412\n",
      "[Iter: 15000], [Time Elapsed: 403.10s], [Revenue: 0.1193]\n",
      "Updated num_menus from 412 --->: 388\n",
      "[Iter: 16000], [Time Elapsed: 419.22s], [Revenue: 0.1196]\n",
      "Updated num_menus from 388 --->: 367\n",
      "[Iter: 17000], [Time Elapsed: 434.28s], [Revenue: 0.1195]\n",
      "Updated num_menus from 367 --->: 346\n",
      "[Iter: 18000], [Time Elapsed: 448.63s], [Revenue: 0.1185]\n",
      "Updated num_menus from 346 --->: 325\n",
      "[Iter: 19000], [Time Elapsed: 462.21s], [Revenue: 0.1186]\n",
      "Updated num_menus from 325 --->: 305\n",
      "[Iter: 20000], [Time Elapsed: 474.84s], [Revenue: 0.1191]\n",
      "Updated num_menus from 305 --->: 288\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "                                  \n",
    "while it <= cfg.max_iter:\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    theta = torch_var(sample_batch(cfg.batch_size))\n",
    "    rev = net(theta).mean()\n",
    "    loss = -rev\n",
    "    loss.backward()   \n",
    "    opt.step()\n",
    "    \n",
    "    if it % cfg.print_iter == 0:\n",
    "        print(\"[Iter: %d], [Time Elapsed: %.2fs], [Revenue: %.4f]\"%(it, time.time() - tic, rev.item()))\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        \n",
    "        # Delete duplicates\n",
    "        net.delete_duplicates()\n",
    "        \n",
    "        # Delete unused menus\n",
    "        \"\"\"\n",
    "        used_menus = torch_var(np.zeros((net.pi.shape[0] + 1)))\n",
    "        with torch.no_grad():\n",
    "            pi_menu, pay_menu = net.get_menu()\n",
    "            for _ in range(cfg.tst_num_batches):\n",
    "                theta = torch_var(sample_batch(cfg.batch_size))\n",
    "                utility = torch.max(theta[:, None, :, None] * pi_menu, axis = -2)[0].sum(axis = -1) - pay_menu[None, :]\n",
    "                menu_idx = F.softmax(net.u_temp_inv * utility, dim = -1)\n",
    "                menu_idx.data[menu_idx.data < 0.001] = 0.0\n",
    "                used_menus += menu_idx.sum(axis = 0)\n",
    "\n",
    "            used_menus = used_menus/(cfg.tst_num_batches * cfg.batch_size)\n",
    "    \n",
    "            net.pi = net.pi[used_menus[:-1] > 1e-3]\n",
    "            net.pay = net.pay[used_menus[:-1] > 1e-3]\n",
    "        \n",
    "        net.pi.requires_grad = True\n",
    "        net.pay.requires_grad = True\n",
    "        net.num_menus = net.pi.shape[0]\n",
    "        print(\"Deleted unused menus. Current: %d\"%(net.num_menus))\n",
    "        \n",
    "        if it <= 5000:\n",
    "            lr = 5e-4\n",
    "        else:\n",
    "            lr = 2e-4\n",
    "            \n",
    "        opt = torch.optim.RMSprop([net.pi, net.pay], lr = lr )\n",
    "        \"\"\"\n",
    "        \n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "718dc33e-47cc-48c6-be34-2a5d03e07195",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_menu, pay_menu = net.get_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abe2bdc1-514f-44f6-9ea0-2497e42494bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[    0.9998,     0.0002,     0.0000],\n",
       "          [    0.0000,     1.0000,     0.0000],\n",
       "          [    0.0001,     0.0000,     0.9999]],\n",
       " \n",
       "         [[    0.9999,     0.0000,     0.0001],\n",
       "          [    0.0000,     1.0000,     0.0000],\n",
       "          [    0.0000,     0.0008,     0.9991]],\n",
       " \n",
       "         [[    0.9997,     0.0002,     0.0001],\n",
       "          [    0.0002,     0.9998,     0.0000],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    0.9994,     0.0001,     0.0005],\n",
       "          [    0.0000,     1.0000,     0.0000],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    0.9999,     0.0000,     0.0001],\n",
       "          [    0.0000,     1.0000,     0.0000],\n",
       "          [    0.0000,     0.0000,     0.9999]],\n",
       " \n",
       "         [[    0.9998,     0.0000,     0.0001],\n",
       "          [    0.0000,     0.9999,     0.0001],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    0.9999,     0.0001,     0.0000],\n",
       "          [    0.0000,     0.9998,     0.0002],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    1.0000,     0.0000,     0.0000],\n",
       "          [    0.0000,     1.0000,     0.0000],\n",
       "          [    0.0000,     0.0006,     0.9994]],\n",
       " \n",
       "         [[    0.9998,     0.0000,     0.0002],\n",
       "          [    0.0001,     0.9999,     0.0001],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    0.9999,     0.0001,     0.0000],\n",
       "          [    0.0000,     0.9999,     0.0001],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    0.9998,     0.0000,     0.0002],\n",
       "          [    0.0001,     0.9999,     0.0000],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    0.9999,     0.0000,     0.0000],\n",
       "          [    0.0002,     0.9998,     0.0000],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    0.9998,     0.0000,     0.0002],\n",
       "          [    0.0002,     0.9998,     0.0000],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    0.9999,     0.0001,     0.0000],\n",
       "          [    0.0000,     0.9998,     0.0002],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    1.0000,     0.0000,     0.0000],\n",
       "          [    0.0000,     0.9998,     0.0002],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    1.0000,     0.0000,     0.0000],\n",
       "          [    0.0000,     0.9998,     0.0002],\n",
       "          [    0.0000,     0.0000,     1.0000]],\n",
       " \n",
       "         [[    0.3333,     0.3333,     0.3333],\n",
       "          [    0.3333,     0.3333,     0.3333],\n",
       "          [    0.3333,     0.3333,     0.3333]]], device='cuda:0',\n",
       "        grad_fn=<SoftmaxBackward0>),\n",
       " tensor([0.2356, 0.2364, 0.2364, 0.2364, 0.2358, 0.2356, 0.2356, 0.2364, 0.2364,\n",
       "         0.2364, 0.2356, 0.2356, 0.2364, 0.2364, 0.2364, 0.2356, 0.0000],\n",
       "        device='cuda:0', grad_fn=<CatBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_menu, pay_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efe0b3f1-3bcf-4287-826c-64bc3bbf1adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted unused menus. Current: 16\n"
     ]
    }
   ],
   "source": [
    "used_menus = torch_var(np.zeros((net.pi.shape[0] + 1)))\n",
    "with torch.no_grad():\n",
    "    pi_menu, pay_menu = net.get_menu()\n",
    "    for _ in range(cfg.tst_num_batches):\n",
    "        theta = torch_var(sample_batch(cfg.batch_size))\n",
    "        utility = torch.max(theta[:, None, :, None] * pi_menu, axis = -2)[0].sum(axis = -1) - pay_menu[None, :]\n",
    "        menu_idx = F.softmax(net.u_temp_inv * utility, dim = -1)\n",
    "        menu_idx.data[menu_idx.data < 0.001] = 0.0\n",
    "        used_menus += menu_idx.sum(axis = 0)\n",
    "\n",
    "    used_menus = used_menus/(cfg.tst_num_batches * cfg.batch_size)\n",
    "\n",
    "    net.pi = net.pi[used_menus[:-1] > 1e-2]\n",
    "    net.pay = net.pay[used_menus[:-1] > 1e-2]\n",
    "\n",
    "net.pi.requires_grad = True\n",
    "net.pay.requires_grad = True\n",
    "net.num_menus = net.pi.shape[0]\n",
    "print(\"Deleted unused menus. Current: %d\"%(net.num_menus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3603a4a8-1e03-4490-bf3e-3119b02636a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
       "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0001,\n",
       "            0.0001,     0.0001,     0.0001,     0.0001,     0.0001,     0.0001,\n",
       "            0.0001,     0.0001,     0.0001,     0.0001,     0.0001,     0.0001,\n",
       "            0.0001,     0.0002,     0.0002,     0.0002,     0.0002,     0.0002,\n",
       "            0.0002,     0.0002,     0.0002,     0.0002,     0.0002,     0.0002,\n",
       "            0.0002,     0.0002,     0.0002,     0.0002,     0.0002,     0.0004,\n",
       "            0.0004,     0.0005,     0.0005,     0.0006,     0.0006,     0.0006,\n",
       "            0.0006,     0.0006,     0.0007,     0.0007,     0.0007,     0.0007,\n",
       "            0.0007,     0.0007,     0.0007,     0.0007,     0.0008,     0.0008,\n",
       "            0.0010,     0.0010,     0.0010,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0012,     0.0012,     0.0012,\n",
       "            0.0012,     0.0012,     0.0012,     0.0014,     0.0014,     0.0014,\n",
       "            0.0014,     0.0014,     0.0014,     0.0014,     0.0014,     0.0014,\n",
       "            0.0014,     0.0014,     0.0014,     0.0014,     0.0014,     0.0014,\n",
       "            0.0014,     0.0014,     0.0014,     0.0014,     0.0014,     0.0014,\n",
       "            0.0014,     0.0014,     0.0014,     0.0014,     0.0014,     0.0015,\n",
       "            0.0015,     0.0016,     0.0016,     0.0017,     0.0017,     0.0018,\n",
       "            0.0018,     0.0018,     0.0019,     0.0019,     0.0019,     0.0019,\n",
       "            0.0019,     0.0019,     0.0019,     0.0019,     0.0019,     0.0019,\n",
       "            0.0019,     0.0019,     0.0020,     0.0020,     0.0020,     0.0020,\n",
       "            0.0020,     0.0020,     0.0020,     0.0020,     0.0020,     0.0020,\n",
       "            0.0020,     0.0020,     0.0020,     0.0020,     0.0020,     0.0021,\n",
       "            0.0021,     0.0023,     0.0024,     0.0024,     0.0031,     0.0043,\n",
       "            0.0046,     0.0050,     0.0051,     0.0052,     0.0052,     0.0052,\n",
       "            0.0053,     0.0053,     0.0202,     0.0208,     0.0216,     0.0217,\n",
       "            0.0217,     0.0217,     0.0218,     0.0218,     0.0218,     0.0247,\n",
       "            0.0254,     0.0255,     0.0255,     0.0255,     0.0255,     0.0255,\n",
       "            0.3174], device='cuda:0', dtype=torch.float64),\n",
       "indices=tensor([  8,   9,  59,  78,  79,  81,  85,  86, 116, 119, 130, 146, 152, 191,\n",
       "        200, 203, 212, 217, 224, 248, 254, 250, 213,  40,  64, 259, 188, 164,\n",
       "        262, 270, 171, 204, 242, 283,  49, 275, 278, 252, 192, 147, 235,  24,\n",
       "        195, 271, 269,  83,  62, 198, 159, 144,  67, 140,  41,  73, 100, 243,\n",
       "         93,  30,  47,  45,  92, 180,  15, 156, 232, 168,  12, 162, 206, 222,\n",
       "        173,   5, 207,  35,   7,   4, 118, 129, 117, 125, 194,  43,  56,  20,\n",
       "        234, 218,  65, 225, 163, 209,  21,  61, 124,  22,  74, 115, 187, 276,\n",
       "        285,  34, 185,  58, 202,  48, 143,  26, 109, 251, 201,  28,  96, 190,\n",
       "         37, 108, 103,  76,  25, 161,  95, 134,  90,  66, 227, 179, 220, 138,\n",
       "         23, 264,  55, 155, 132, 154,  10, 226,  46, 236, 265, 199, 153,  75,\n",
       "         42, 105,  11, 274, 137,   0, 246, 205, 277, 145, 266,  99, 110, 256,\n",
       "        237, 219,  16, 214,  53, 178,  38, 104, 122,  80,  70, 268,  54, 142,\n",
       "        267,  19, 223, 166, 229, 151, 174, 114, 193, 280,  88, 261, 286,  97,\n",
       "        255, 238, 240, 233, 112, 186,  18,  27,  31, 216, 244, 113,  71,  36,\n",
       "        148, 228, 182, 175, 210, 183, 260, 208, 111, 211, 272, 253,   1, 158,\n",
       "          3,  89, 127,  87, 139, 170,  60, 167, 128, 258, 231,  82, 287, 120,\n",
       "        189,  69, 133, 106,   6, 172, 101, 177,  98,  50, 102,  13, 245, 247,\n",
       "         77,  51, 150,  52,  91,  17, 136,  94, 281, 123, 230,  84, 169,  33,\n",
       "        165, 126, 263, 221,  14, 107, 141,  29, 273, 241,   2, 157, 184, 160,\n",
       "        121,  68,  63, 176, 149,  72,  39, 196,  57,  44, 257, 197, 215, 282,\n",
       "        279, 131,  32, 284, 249, 135, 181, 239, 288], device='cuda:0'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_menus.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9a8cd-3959-4d33-a3ef-ad8e7216e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 1000] = 0.001\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-data_markets]",
   "language": "python",
   "name": "conda-env-.conda-data_markets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
