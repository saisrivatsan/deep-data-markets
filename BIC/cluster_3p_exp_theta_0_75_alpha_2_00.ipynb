{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "90a42f82-5981-4236-85c2-db2be1c59143"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.set_printoptions(sci_mode = False, precision = 4)"
      ],
      "id": "90a42f82-5981-4236-85c2-db2be1c59143"
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "18a2722d-fb74-4b97-a8b6-e8f3bbc1fe26"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "class HParams:\n",
        "    def __init__(self):\n",
        "        \n",
        "        # Problem params\n",
        "        self.num_agents = 3\n",
        "        self.num_states = 2\n",
        "        self.num_signals = 2\n",
        "        \n",
        "        self.theta = np.array([0.75, 0.25])\n",
        "        self.alpha = 2\n",
        "        \n",
        "        # Minibatch size\n",
        "        self.batch_size = 50\n",
        "        \n",
        "        # Number of samples for computing interim vals\n",
        "        self.num_samples = 1400\n",
        "        \n",
        "        # Number of layer\n",
        "        self.R = 3\n",
        "        # Number of hidden units\n",
        "        self.K = 200\n",
        "        \n",
        "        # Data - Choose among exp, uniform, asym_uniform, irregular\n",
        "        self.distr_type = \"exp\"\n",
        "        \n",
        "        # Opt params\n",
        "        self.lr = 8e-4\n",
        "        \n",
        "        self.gd_lr = 5e-3\n",
        "        self.gd_iter = 5\n",
        "        \n",
        "        # Lagrangian params\n",
        "        \n",
        "        self.lag_ob_init = 5\n",
        "        self.lag_ir_init = 5\n",
        "        self.lag_ic_init = 5\n",
        "        \n",
        "        self.lag_up_iter = 200\n",
        "        \n",
        "        self.pho_init = 10\n",
        "        \n",
        "        self.pho_increment = 10\n",
        "        self.pho_up_iter = 200\n",
        "        \n",
        "        # Miscellaneous\n",
        "        self.seed = 0\n",
        "                  \n",
        "        self.max_iter = 60000 \n",
        "        self.print_iter = 1000\n",
        "                \n",
        "# Initialize config\n",
        "cfg = HParams()\n",
        "np.random.seed(cfg.seed)\n",
        "\n",
        "# Asserts\n",
        "# assert(cfg.num_agents == 2)\n",
        "device = \"cuda\"\n",
        "\n",
        "np.random.seed(cfg.seed)"
      ],
      "id": "18a2722d-fb74-4b97-a8b6-e8f3bbc1fe26"
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "43976218-80e7-4f72-a617-230515a16c5a"
      },
      "outputs": [],
      "source": [
        "def sampler_exp(idx, batch_size):\n",
        "    return np.random.exponential(scale = 1.0, size = (batch_size))\n",
        "\n",
        "def sampler_uniform(idx, batch_size):\n",
        "    return np.random.uniform(low = 0.0, high = 1.0, size = (batch_size))\n",
        "\n",
        "def sampler_asym_uniform(idx, batch_size):\n",
        "    return np.random.uniform(low = 0.0, high = idx + 1.0, size = (batch_size))\n",
        "\n",
        "def sampler_irr(idx, batch_size):    \n",
        "    sample_1 = np.random.uniform(low = 0.0, high = 3.0, size = (batch_size))\n",
        "    sample_2 = np.random.uniform(low = 3.0, high = 8.0, size = (batch_size))\n",
        "    mask = np.random.binomial(1, 0.75, (batch_size))\n",
        "    return (sample_1 * mask + sample_2 * (1 - mask))/10 \n",
        "\n",
        "if cfg.distr_type == \"exp\":\n",
        "    samplers = sampler_exp\n",
        "\n",
        "if cfg.distr_type == \"uniform\":\n",
        "    samplers = sampler_uniform\n",
        "        \n",
        "if cfg.distr_type == \"asym_uniform\":\n",
        "    samplers = sampler_asym_uniform\n",
        "    \n",
        "if cfg.distr_type == \"irregular\":\n",
        "    samplers = sampler_irr"
      ],
      "id": "43976218-80e7-4f72-a617-230515a16c5a"
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "f64e49ab-1323-4a63-93fb-2d1226ee7414"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "def torch_var(x): return torch.Tensor(x).to(device)\n",
        "def numpy_var(x): return x.detach().cpu().numpy()\n",
        "\n",
        "# Broadcasting into [n, 1] for easy multiplication\n",
        "theta = torch_var(cfg.theta)[:, None]"
      ],
      "id": "f64e49ab-1323-4a63-93fb-2d1226ee7414"
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "5522870a-54bb-40f9-801e-01d1a1a828b8"
      },
      "outputs": [],
      "source": [
        "# TODO: Initializations, Softmax temperatures\n",
        "\n",
        "class PiNet(nn.Module):      \n",
        "    def __init__(self, cfg):\n",
        "        super(PiNet, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        \n",
        "        num_agents = self.cfg.num_agents\n",
        "        num_states = self.cfg.num_states\n",
        "        num_signals = self.cfg.num_signals\n",
        "        \n",
        "        num_layers = self.cfg.R\n",
        "        num_hidden_nodes = self.cfg.K\n",
        "\n",
        "        self.pi = nn.ModuleList()\n",
        "        \n",
        "        # Input layer\n",
        "        self.pi.append(nn.Linear(num_agents, num_hidden_nodes))\n",
        "        self.pi.append(nn.LeakyReLU())\n",
        "        \n",
        "        # Hidden layers\n",
        "        for i in range(num_layers - 1):\n",
        "            self.pi.append(nn.Linear(num_hidden_nodes, num_hidden_nodes))\n",
        "            self.pi.append(nn.LeakyReLU())\n",
        "         \n",
        "        # Output layer\n",
        "        self.pi.append(nn.Linear(num_hidden_nodes, num_agents * num_states * num_signals))\n",
        "        \n",
        "        for m in self.pi:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "    def forward(self, v):\n",
        "        out = v\n",
        "        for module in self.pi: out = module(out)\n",
        "        out = out.view(-1, self.cfg.num_agents, self.cfg.num_states, self.cfg.num_signals)\n",
        "        return F.softmax(out, dim = -1)\n",
        "    \n",
        "    \n",
        "class PayNet(nn.Module):     \n",
        "    def __init__(self, cfg):\n",
        "        super(PayNet, self).__init__()\n",
        "        self.cfg = cfg        \n",
        "        num_layers = self.cfg.R\n",
        "        num_hidden_nodes = self.cfg.K\n",
        "\n",
        "        self.pay = nn.ModuleList()\n",
        "        \n",
        "        # Input layer\n",
        "        self.pay.append(nn.Linear(1, num_hidden_nodes))\n",
        "        self.pay.append(nn.LeakyReLU())\n",
        "        \n",
        "        # Hidden layers\n",
        "        for i in range(num_layers - 1):\n",
        "            self.pay.append(nn.Linear(num_hidden_nodes, num_hidden_nodes))\n",
        "            self.pay.append(nn.LeakyReLU())\n",
        "         \n",
        "        # Output layer\n",
        "        self.pay.append(nn.Linear(num_hidden_nodes, 1))\n",
        "        self.pay.append(nn.Sigmoid())\n",
        "        \n",
        "        for m in self.pay:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        \n",
        "    def forward(self, v):\n",
        "        out = v[:, None]\n",
        "        for module in self.pay: out = module(out)\n",
        "        return out.flatten()"
      ],
      "id": "5522870a-54bb-40f9-801e-01d1a1a828b8"
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "893b54b6-3543-4735-8e71-96981bd25678"
      },
      "outputs": [],
      "source": [
        "def compute_x_interim(pi_interim):\n",
        "    \"\"\"\n",
        "    Computes interim probability of taking the correct action \n",
        "    assuming obedience is satified\n",
        "    \n",
        "    Args:\n",
        "        pi_interim: [Batch_size, Num_States, Num_Signals]\n",
        "    Returns:\n",
        "        x_interim: [Batch_size]\n",
        "    \"\"\"\n",
        "    \n",
        "    return torch.diagonal(pi_interim * theta, offset = 0, dim1 = -2, dim2 = -1).sum(-1)\n",
        "\n",
        "def compute_x_deviation(pi_interim):\n",
        "    \"\"\"\n",
        "    Computes interim probability of taking the correct action \n",
        "    when obedience is not imposed    \n",
        "    Args:\n",
        "        pi_interim: [Batch_size, Num_States, Num_Signals]\n",
        "    Returns:\n",
        "        x_deviation: [Batch_size]\n",
        "    \"\"\"\n",
        "    \n",
        "    return torch.max(pi_interim * theta, axis = -2)[0].sum(-1)\n",
        "\n",
        "\n",
        "def compute_obedience_violations(x_interim, pi_interim):\n",
        "    \"\"\"\n",
        "    Computes obedience violation\n",
        "    Args:\n",
        "        x_inteirm: [Batch]\n",
        "    Returns:\n",
        "        ob_viol: [Batch]\n",
        "    \"\"\"\n",
        "\n",
        "    x_deviation = compute_x_deviation(pi_interim) \n",
        "    ob_viol = F.relu(x_deviation - x_interim)\n",
        "    return ob_viol"
      ],
      "id": "893b54b6-3543-4735-8e71-96981bd25678"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "ca06b82e-4bc9-414b-9d72-40449fe5f3c2"
      },
      "outputs": [],
      "source": [
        "def compute_payments_from_fractions(v_i, payoff_interim, i):\n",
        "    \"\"\"\n",
        "    Computes interim payments from pay_frac\n",
        "    Args:\n",
        "        v_i: [Batch]\n",
        "        payoff_interim: [Batch]\n",
        "        pay_frac: [Batch]\n",
        "    Returns:\n",
        "        payment_interim: [Batch]\n",
        "    \"\"\"\n",
        "    \n",
        "    # Compute p_frac\n",
        "    pay_frac = pay_net[i](v_i)\n",
        "    \n",
        "    # Payoff if opting out\n",
        "    payoff_out = max(cfg.theta) - cfg.alpha\n",
        "    \n",
        "    \"\"\" \n",
        "    Pay <= Utility - Utility_out \n",
        "         = v_i * (payoff_interim - pay_out)     \n",
        "    \"\"\"\n",
        "    \n",
        "    payment_interim = v_i * (payoff_interim - payoff_out) * pay_frac\n",
        "    return payment_interim"
      ],
      "id": "ca06b82e-4bc9-414b-9d72-40449fe5f3c2"
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "f5151d96-0b8d-4712-93af-1502d7f2d23d"
      },
      "outputs": [],
      "source": [
        "def compute_ir_violation(v_i, payoff_interim, pay_interim):\n",
        "    \"\"\"\n",
        "    Computes IR violation\n",
        "    Args:\n",
        "        v_i: [Batch]\n",
        "        payoff_interim: [Batch]\n",
        "        pay_interim: [Batch]\n",
        "    Returns:\n",
        "        ir_viol: [Batch]\n",
        "    \"\"\"\n",
        "    \n",
        "    # Payoff if opting out\n",
        "    payoff_out = max(cfg.theta) - cfg.alpha    \n",
        "    ir_viol = F.relu( v_i * (payoff_out - payoff_interim) + pay_interim )\n",
        "    return ir_viol"
      ],
      "id": "f5151d96-0b8d-4712-93af-1502d7f2d23d"
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "8b93d976-9f4e-4e28-bde8-3edada270d5a"
      },
      "outputs": [],
      "source": [
        "def compute_ic_violation_grid(v_i, payoff_interim, pay_interim):\n",
        "    \"\"\"\n",
        "    Computes IC violation\n",
        "    Args:\n",
        "        v_i: [Batch]\n",
        "        payoff_interim: [Batch]\n",
        "        pay_interim: [Batch]\n",
        "    Returns:\n",
        "        ic_viol: [Batch]\n",
        "        v_mis: [Batch]\n",
        "\n",
        "    Compute v - payoff outer-product and subtract payment\n",
        "    Now we have a utility Mesh u_mesh whose i'th row j'th column has\n",
        "    the value v[i] * payoff[j] - pay[j]. This is exactly the utility of misreporting with b[i] = v[j]\n",
        "    The diagonal is the utility of truthful reporting. (as b[i] = v[i])\n",
        "    Compute ic_violation as max of misreporting - diagonal value.\n",
        "    \n",
        "    We can use this to warm-start GD: To be implemented\n",
        "    \"\"\"\n",
        "\n",
        "    u_mesh = v_i[:, None] * payoff_interim[None, :] - pay_interim[None, :]\n",
        "    \n",
        "    u_true = torch.diag(u_mesh)\n",
        "    u_mis, v_mis_idx =  u_mesh.max(axis = -1)\n",
        "    v_mis = v_i[v_mis_idx]\n",
        "    \n",
        "    ic_viol = F.relu(u_mis - u_true)\n",
        "    return ic_viol, v_mis.detach()"
      ],
      "id": "8b93d976-9f4e-4e28-bde8-3edada270d5a"
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "71c0ef64-7a0d-4cae-b56d-a4bfd7f355d9"
      },
      "outputs": [],
      "source": [
        "def compute_misreports_gd(v_i, v_mis_i, v_mesh_i, i, gd_lr = 5e-3, gd_iter = 100):\n",
        "    \n",
        "    # Autograd variables\n",
        "    v_mis_i = v_mis_i.detach().clone()\n",
        "    v_mis_i.requires_grad_(True)\n",
        "    \n",
        "    # Optimizer\n",
        "    opt = torch.optim.Adam([v_mis_i], gd_lr)\n",
        "    \n",
        "    for it in range(gd_iter):\n",
        "        \n",
        "        opt.zero_grad()        \n",
        "        u_mis = torch.zeros(cfg.num_agents).to(device)\n",
        "        \n",
        "        # Compose misreport - v_mesh [NA, BS, NS, NA]\n",
        "        v_mesh_mis = torch.cat((v_mesh_i[:, :, :i], v_mis_i[:, None, None].repeat(1, cfg.num_samples, 1), v_mesh_i[:, :, i + 1:]), axis = -1)\n",
        "        \n",
        "        pi_mesh_mis = pi_net(v_mesh_mis.view(-1, cfg.num_agents)).view(cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)\n",
        "        pi_interim_mis = pi_mesh_mis.mean(axis = -4)\n",
        "\n",
        "        #x_interim: [Batch_size, Num_agents], Probability of taking correct actions\n",
        "        x_interim_all_mis = compute_x_interim(pi_interim_mis) \n",
        "\n",
        "        # payoff_interim: x_i - \\alpha * \\sum_j != i x_j = (1 + \\alpha) x_i - (\\sum_j) x_j\n",
        "        payoff_interim_mis = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all_mis[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all_mis.sum(axis = -1)\n",
        "\n",
        "        # Compute payments\n",
        "        pay_interim_mis = compute_payments_from_fractions(v_mis_i, payoff_interim_mis, i)\n",
        "\n",
        "        u_mis = (v_i * payoff_interim_mis - pay_interim_mis).sum()\n",
        "            \n",
        "        u_mis_loss = (-u_mis.sum())\n",
        "        u_mis_loss.backward(inputs = v_mis_i)\n",
        "        opt.step()        \n",
        "        v_mis_i.data.clamp_(min = 0.0)\n",
        "        \n",
        "        \n",
        "    return v_mis_i.detach().clone()"
      ],
      "id": "71c0ef64-7a0d-4cae-b56d-a4bfd7f355d9"
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "77ac7f7d-88b2-4852-b12d-a240d94a4684"
      },
      "outputs": [],
      "source": [
        "def compute_ic_viol(v_i, payoff_interim, pay_interim, v_mis_i, v_mesh_i, i):\n",
        "    \n",
        "    v_mesh_mis = torch.cat((v_mesh_i[:, :, :i], v_mis_i[:, None, None].repeat(1, cfg.num_samples, 1), v_mesh_i[:, :, i + 1:]), axis = -1)\n",
        "    \n",
        "    # Compute interim pi_mis\n",
        "    pi_mesh_mis = pi_net(v_mesh_mis.view(-1, cfg.num_agents)).view(cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)\n",
        "    pi_interim_mis = pi_mesh_mis.mean(axis = -4)\n",
        "    \n",
        "    # Compute x_interim_mis, payoff_interim_mis, pay_interim_mis\n",
        "    x_interim_all_mis = compute_x_interim(pi_interim_mis)\n",
        "    payoff_interim_mis = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all_mis[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all_mis.sum(axis = -1)\n",
        "    pay_interim_mis = compute_payments_from_fractions(v_mis_i, payoff_interim_mis, i)\n",
        "    \n",
        "    # Compute u_mis\n",
        "    u_mis = (v_i * payoff_interim_mis - pay_interim_mis)\n",
        "    \n",
        "    # Compute u_true\n",
        "    u_true = v_i * payoff_interim - pay_interim\n",
        "    \n",
        "    # Compute ic_viol\n",
        "    ic_viol = F.relu(u_mis - u_true)\n",
        "    return ic_viol"
      ],
      "id": "77ac7f7d-88b2-4852-b12d-a240d94a4684"
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "a8e2a3e3-6c3e-4759-9169-9b86b3288396"
      },
      "outputs": [],
      "source": [
        "pi_net = PiNet(cfg).to(device)\n",
        "pay_net = [PayNet(cfg).to(device) for _ in range(cfg.num_agents)]\n",
        "# Keep in mind that if the distributions are asymetric, we need two different neural networks"
      ],
      "id": "a8e2a3e3-6c3e-4759-9169-9b86b3288396"
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "708c034f-8d53-4fa1-a6bb-c1b6f4afb75d"
      },
      "outputs": [],
      "source": [
        "lag_ob_init = cfg.lag_ob_init\n",
        "lag_ir_init = cfg.lag_ir_init\n",
        "lag_ic_init = cfg.lag_ic_init\n",
        "\n",
        "pho = cfg.pho_init\n",
        "pho_increment = cfg.pho_increment\n",
        "\n",
        "w_ob = torch.ones(cfg.num_agents).to(device) * lag_ob_init\n",
        "w_ir = torch.ones(cfg.num_agents).to(device) * lag_ir_init\n",
        "w_ic = torch.ones(cfg.num_agents).to(device) * lag_ic_init\n",
        "\n",
        "params = []\n",
        "params.extend(list(pi_net.parameters()))\n",
        "for i in range(cfg.num_agents):\n",
        "    params.extend(list(pay_net[i].parameters()))\n",
        "    \n",
        "opt = torch.optim.AdamW(params, lr=cfg.lr)\n",
        "\n",
        "it = 1"
      ],
      "id": "708c034f-8d53-4fa1-a6bb-c1b6f4afb75d"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "27bda925-6cf4-405f-9a11-6411000417f3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "V_sample is a tensor of shape [num_agents, batch_size and num_samples].\n",
        "V_sample[i, :, :] contains 'num_samples' samples of agent i's valuation to be averaged over \n",
        "for the computation of interim values of the remaning agents. These samples are the same \n",
        "for every valuation profile in the minibatch. (i.e V[i, j, :] = V[i, k, :] )\n",
        "\"\"\"\n",
        "V_sample = np.zeros((cfg.num_agents, cfg.batch_size, cfg.num_samples))\n",
        "\n",
        "for i in range(cfg.num_agents):\n",
        "    V_sample[i] = np.tile(samplers(i, cfg.num_samples)[None, :], (cfg.batch_size, 1))"
      ],
      "id": "27bda925-6cf4-405f-9a11-6411000417f3"
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "100929ff-9541-4af8-ba94-750010e83e2b",
        "outputId": "9ecf8a58-722f-43d7-88e2-aa9099e28add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iter: 48000], [Time Elapsed: 81.92s]\n",
            "[Rev: 1.4948], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 49000], [Time Elapsed: 181.34s]\n",
            "[Rev: 1.4225], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 50000], [Time Elapsed: 280.64s]\n",
            "[Rev: 1.5864], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-f2cdb2cc5636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_mis_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_ic_violation_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayoff_interim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpay_interim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mv_mis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_misreports_gd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_mis_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_mesh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgd_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgd_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgd_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgd_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mic_viol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_ic_viol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayoff_interim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpay_interim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_mis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_mesh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-cf4fe5aa46dd>\u001b[0m in \u001b[0;36mcompute_misreports_gd\u001b[0;34m(v_i, v_mis_i, v_mesh_i, i, gd_lr, gd_iter)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mu_mis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Compose misreport - v_mesh [NA, BS, NS, NA]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "tic = time.time()\n",
        "                                  \n",
        "while it <= cfg.max_iter:\n",
        "    \n",
        "    \n",
        "    opt.zero_grad()\n",
        "    \n",
        "    \"\"\" \n",
        "    Construction of V_mesh:\n",
        "    V_mesh is of shape [num_agents, batch_size, num_samples, num_agents]\n",
        "    What's V_mesh[i, j, k, l]?\n",
        "    V[i, j] - has num_samples elements with the same valuation for agent - i\n",
        "    but with num_samples values from the V_sample array for other agents\n",
        "    \n",
        "    We use this for computation of payment, ic-viol, ob-viol for agent - i only\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    V = np.zeros((cfg.num_agents, cfg.batch_size))\n",
        "    V_mesh = np.zeros((cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents))\n",
        "\n",
        "\n",
        "    for i in range(cfg.num_agents):\n",
        "        V[i] = samplers(i, cfg.batch_size) \n",
        "        for j in range(cfg.num_agents):\n",
        "            if i == j:    \n",
        "                V_mesh[i, :, :, j] = np.tile(V[i][:, None], (1, cfg.num_samples))\n",
        "            else:\n",
        "                V_mesh[i, :, :, j] = V_sample[j]\n",
        "           \n",
        "    v = torch_var(V)\n",
        "    v_mesh = torch_var(V_mesh)\n",
        "    \n",
        "    \n",
        "    pi_mesh = pi_net(v_mesh.view(-1, cfg.num_agents)).view(cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)   \n",
        "    pi_mesh = pi_mesh.mean(axis = -4)\n",
        "        \n",
        "    revenue = torch.zeros(cfg.num_agents).to(device)\n",
        "    ob_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ir_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ic_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(cfg.num_agents):\n",
        "                \n",
        "        #pi_interim: [Batch_size, Num_agents, Num_states, Num_signals], experiments assigned\n",
        "        pi_interim = pi_mesh[i] \n",
        "        \n",
        "        #x_interim: [Batch_size, Num_agents], Probability of taking correct actions\n",
        "        x_interim_all = compute_x_interim(pi_interim) \n",
        "        \n",
        "        # payoff_interim: x_i - \\alpha * \\sum_j != i x_j = (1 + \\alpha) x_i - (\\sum_j) x_j\n",
        "        payoff_interim = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all.sum(axis = -1)\n",
        "        \n",
        "        # Compute payments\n",
        "        pay_interim = compute_payments_from_fractions(v[i], payoff_interim, i)\n",
        "        \n",
        "        # Compute Revenue        \n",
        "        revenue[i] = pay_interim.mean()\n",
        "        \n",
        "        # Compute obedience violations\n",
        "        ob_viol[i] = compute_obedience_violations(x_interim_all[:, i], pi_interim[:, i]).mean()\n",
        "        \n",
        "        # Compute ir violation\n",
        "        ir_viol[i] = compute_ir_violation(v[i], payoff_interim, pay_interim).mean()\n",
        "        \n",
        "        # Compute ic violation: \n",
        "        # Uncomment this for random starts\n",
        "        # v_mis_init = torch_var(samplers(i,cfg.batch_size))\n",
        "        \n",
        "        # Warm-start with the best misreport computed using other minibatch vals\n",
        "        _, v_mis_init = compute_ic_violation_grid(v[i], payoff_interim, pay_interim)\n",
        "                \n",
        "        v_mis = compute_misreports_gd(v[i], v_mis_init, v_mesh[i], i, gd_lr = cfg.gd_lr, gd_iter = cfg.gd_iter)        \n",
        "        ic_viol[i] = compute_ic_viol(v[i], payoff_interim, pay_interim, v_mis, v_mesh[i], i).mean()\n",
        "    \n",
        "\n",
        "    rev_loss = -revenue.sum()\n",
        "    lagrangian = torch.dot(w_ob, ob_viol) + torch.dot(w_ir, ir_viol) + torch.dot(w_ic, ic_viol)\n",
        "    penalty = pho * ((ob_viol**2).sum() + (ir_viol**2).sum() + (ic_viol**2).sum())\n",
        "    \n",
        "    loss = rev_loss + penalty + lagrangian\n",
        "    \n",
        "    loss.backward()   \n",
        "    opt.step()\n",
        "    \n",
        "    if it % cfg.print_iter == 0:\n",
        "        print(\"[Iter: %d], [Time Elapsed: %.2fs]\"%(it, time.time() - tic))\n",
        "        print(\"[Rev: %.4f], [OB Viol: %.4f], [IR Viol: %.4f], [IC Viol: %.4f]\"%(revenue.sum(), ob_viol.mean().item(), ir_viol.mean().item(), ic_viol.mean().item()))\n",
        "        \n",
        "    if it % cfg.lag_up_iter == 0:\n",
        "        w_ob.data += pho * ob_viol.data\n",
        "        w_ic.data += pho * ic_viol.data\n",
        "        \n",
        "    if it % cfg.pho_up_iter == 0:\n",
        "        pho += pho_increment\n",
        "        \n",
        "    it += 1"
      ],
      "id": "100929ff-9541-4af8-ba94-750010e83e2b"
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "2c22f1e6-7d2a-49b5-94fa-71802d903559",
        "outputId": "7e9c5d6a-7ed0-461e-b3e0-ac6577ea91b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import scipy.stats\n",
        "D = 81\n",
        "v1 = torch_var(np.linspace(0, 4, D))\n",
        "# v2 = torch_var(np.linspace(0, 0.8, D))\n",
        "s2 = torch_var(np.linspace(0, 8, D))\n",
        "v2 = s2/2\n",
        "v3 = s2.clone()/2\n",
        "v_mesh = torch.stack(torch.meshgrid(v1, v2, indexing = \"ij\"), axis = -1)\n",
        "v_mesh = torch.cat((v_mesh, v_mesh[:,:,1].reshape(D,D,1)),dim=-1)\n",
        "\n",
        "pi_mesh = torch.diagonal(pi_net(v_mesh.view(-1, 3)).view(D, D, cfg.num_agents, cfg.num_states, cfg.num_signals) * theta, 0, -2, -1).sum(-1)\n",
        "AM = numpy_var(pi_mesh)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(ncols = 1, nrows = 1, figsize=(5,4))\n",
        "\n",
        "img_1 = ax.imshow(AM[:, :, 0].transpose(1,0), extent=[0,4,0,8], vmin = 0.0,aspect = 0.5, vmax=1.0, cmap = 'YlOrRd', origin = \"lower\")\n",
        "plt.colorbar(img_1, ax = ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "# img_2 = ax[1].imshow(AM[:, :, 1].transpose(1,0), extent=[0,4,0,8], vmin = 0.0,aspect = 0.5, vmax=1.0, cmap = 'YlOrRd', origin = \"lower\")\n",
        "# plt.colorbar(img_2, ax = ax[1], fraction=0.046, pad=0.04)\n",
        "\n",
        "ax.plot([0, 0.678347], [2.69263, 2.69263], color='black')\n",
        "ax.plot([0.678347, 4],[1.678347, 5],color='black')\n",
        "\n",
        "ax.set_xlabel(\"$v_1$\")\n",
        "ax.set_ylabel(\"$v_{-1}$\")\n",
        "# ax[1].set_xlabel(\"$v_1$\")\n",
        "# ax[1].set_ylabel(\"$v_{-1}$\")\n",
        "\n",
        "fig.text(0.5, 1, r\"Irr, $\\alpha=%.2f, \\theta=%.2f$\"%(cfg.alpha, max(cfg.theta)), ha='center', size = 16)\n",
        "fig.tight_layout()"
      ],
      "id": "2c22f1e6-7d2a-49b5-94fa-71802d903559"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ccc0787-619e-48e7-9ed6-846a834043b6"
      },
      "outputs": [],
      "source": [
        "V = np.linspace(0, 8, 801)\n",
        "V_mesh = np.stack(np.meshgrid(V, V, indexing = \"ij\"), axis = -1)\n",
        "\n",
        "def compute_VV(v):\n",
        "    vv = np.zeros(v.shape)\n",
        "    for i in range(v.shape[0]):\n",
        "        if(v[i] <= (7.0 - np.sqrt(5.0))/2.0):\n",
        "            vv[i] = 2.0 * v[i] - 4.0\n",
        "        elif(v[i] <= (11.0 - np.sqrt(5.0))/2.0):\n",
        "            vv[i] = 3.0 - np.sqrt(5.0)\n",
        "        else:\n",
        "            vv[i] = 2.0 * v[i] - 8.0\n",
        "    return(vv)\n",
        "\n",
        "VV = compute_VV(V)\n",
        "VV_mesh = np.stack(np.meshgrid(VV, VV, indexing = \"ij\"), axis = -1)"
      ],
      "id": "2ccc0787-619e-48e7-9ed6-846a834043b6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b927338-96b3-4e94-95c0-083210d30a82"
      },
      "outputs": [],
      "source": [
        "def compute_alloc(V_mesh, VV_mesh):\n",
        "    x = np.zeros(VV_mesh.shape)\n",
        "    rev = 0.0\n",
        "    for i in range(VV_mesh.shape[0]):\n",
        "        for j in range(VV_mesh.shape[1]):\n",
        "            x[i, j, 0] =  VV_mesh[i, j, 0] > cfg.alpha * VV_mesh[i, j, 1]\n",
        "            x[i, j, 1] =  VV_mesh[i, j, 1] > cfg.alpha * VV_mesh[i, j, 0]\n",
        "            if V_mesh[i, j, 0] <= 2 and V_mesh[i, j, 1] <= 2:\n",
        "               x[i, j, 0] = 1.0\n",
        "               x[i, j, 1] = 1.0\n",
        "            \n",
        "        rev += x[i, j, 0] * (VV_mesh[i, j, 0] - cfg.alpha * VV_mesh[i, j, 1])\n",
        "    return x, rev/(VV_mesh.shape[0] * VV_mesh.shape[1])"
      ],
      "id": "4b927338-96b3-4e94-95c0-083210d30a82"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "592197c8-f26a-41c8-9b1b-e2a012cd2eb0"
      },
      "outputs": [],
      "source": [
        "X, rev = compute_alloc(V_mesh, VV_mesh)\n",
        "print(np.shape(X))"
      ],
      "id": "592197c8-f26a-41c8-9b1b-e2a012cd2eb0"
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iCJE-4A6x-TO",
        "outputId": "89b783b8-c8d0-4fd3-f9ed-67362d64ec6d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fe20fcb6-2fcf-4c93-bb63-1db0cbb683c6\", \"notgoodnnn1.pth\", 337143)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_37dc5b09-f706-4d5a-ae42-664907aa9126\", \"notgoodnnn2.pth\", 326775)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ed59ffbe-76f0-4fa2-803b-478b621e7d74\", \"notgoodnnn3.pth\", 326775)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "torch.save(pi_net.state_dict(), 'notgoodnnn1.pth')\n",
        "torch.save(pay_net[0].state_dict(), 'notgoodnnn2.pth')\n",
        "torch.save(pay_net[1].state_dict(), 'notgoodnnn3.pth')\n",
        "# # # # download checkpoint file\n",
        "files.download('notgoodnnn1.pth')\n",
        "files.download('notgoodnnn2.pth')\n",
        "files.download('notgoodnnn3.pth')\n",
        "# files.upload()\n",
        "# state_dict = torch.load('n3p_exp_theta_0.75_alpha_2.00.pth')\n",
        "# state_dict_2 = torch.load('n3p_exp_theta_0.75_alpha_2.00p1.pth')\n",
        "# state_dict_3 = torch.load('n3p_exp_theta_0.75_alpha_2.00p2.pth')\n",
        "# pi_net.load_state_dict(state_dict)\n",
        "# pay_net[0].load_state_dict(state_dict_2)\n",
        "# pay_net[1].load_state_dict(state_dict_3)"
      ],
      "id": "iCJE-4A6x-TO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8104df4-bb98-40a7-83d2-6539aa0e8625"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X[:, :,0].T, origin = \"lower\")"
      ],
      "id": "a8104df4-bb98-40a7-83d2-6539aa0e8625"
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "id": "0b25b1a1-91fa-42cc-a5ad-3e0074345a90"
      },
      "outputs": [],
      "source": [
        "pho=200"
      ],
      "id": "0b25b1a1-91fa-42cc-a5ad-3e0074345a90"
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "id": "7cc45f8d-2565-4c4a-8ba0-1f000df6251c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75fc2910-b712-4d39-f208-60ea28f6b256"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "755"
            ]
          },
          "metadata": {},
          "execution_count": 417
        }
      ],
      "source": [
        "pho"
      ],
      "id": "7cc45f8d-2565-4c4a-8ba0-1f000df6251c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "232a0050-b215-483c-be6c-dbf0fa73d682"
      },
      "outputs": [],
      "source": [
        "U1 = (VV_mesh[:, :, 0] - 0.5 * VV_mesh[:, :, 1])\n",
        "U2 = (VV_mesh[:201, :201, 0] - 0.5 * VV_mesh[:201, :201, 1])"
      ],
      "id": "232a0050-b215-483c-be6c-dbf0fa73d682"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90a177c2-f1cb-4907-bd32-2930195d2752"
      },
      "outputs": [],
      "source": [
        "X = (U1 > 0)"
      ],
      "id": "90a177c2-f1cb-4907-bd32-2930195d2752"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "138f167e-dfc2-4380-a8ae-8d8ff598d4c8"
      },
      "outputs": [],
      "source": [
        "X[:201, :201] = 1.0"
      ],
      "id": "138f167e-dfc2-4380-a8ae-8d8ff598d4c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "821da283-7851-45ba-9906-b02899e8985e"
      },
      "outputs": [],
      "source": [
        "VV_mesh.shape"
      ],
      "id": "821da283-7851-45ba-9906-b02899e8985e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17037346-43cf-41fb-b33e-92a78b0a3aac"
      },
      "outputs": [],
      "source": [
        "(X * (VV_mesh[:, :, 0] - 0.5 * VV_mesh[:, :, 1])).mean()"
      ],
      "id": "17037346-43cf-41fb-b33e-92a78b0a3aac"
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "84aa220f-a73f-40ed-9066-59a44231abe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24c90a6-d979-4550-d48b-979e8ffda569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Rev: 1.4408], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.4456], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.4434], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.4423], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.4388], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.4391], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.4400], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.4396], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.4389], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.4384], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import gc\n",
        "tic = time.time()\n",
        "                              \n",
        "\n",
        "\"\"\" \n",
        "Construction of V_mesh:\n",
        "V_mesh is of shape [num_agents, batch_size, num_samples, num_agents]\n",
        "What's V_mesh[i, j, k, l]?\n",
        "V[i, j] - has num_samples elements with the same valuation for agent - i\n",
        "but with num_samples values from the V_sample array for other agents\n",
        "\n",
        "We use this for computation of payment, ic-viol, ob-viol for agent - i only\n",
        "\"\"\"\n",
        "ctrrev = 0\n",
        "ctrob = 0\n",
        "ctrir = 0\n",
        "ctric = 0\n",
        "testitr = 10000\n",
        "for iters in range(testitr):\n",
        "    opt.zero_grad()\n",
        "  \n",
        "    \"\"\" \n",
        "    Construction of V_mesh:\n",
        "    V_mesh is of shape [num_agents, batch_size, num_samples, num_agents]\n",
        "    What's V_mesh[i, j, k, l]?\n",
        "    V[i, j] - has num_samples elements with the same valuation for agent - i\n",
        "    but with num_samples values from the V_sample array for other agents\n",
        "    \n",
        "    We use this for computation of payment, ic-viol, ob-viol for agent - i only\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    V = np.zeros((cfg.num_agents, cfg.batch_size))\n",
        "    V_mesh = np.zeros((cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents))\n",
        "\n",
        "\n",
        "    for i in range(cfg.num_agents):\n",
        "        V[i] = samplers(i, cfg.batch_size)    \n",
        "        for j in range(cfg.num_agents):\n",
        "            if i == j:    \n",
        "                V_mesh[i, :, :, j] = np.tile(V[i][:, None], (1, cfg.num_samples))\n",
        "            else:\n",
        "                V_mesh[i, :, :, j] = V_sample[j]\n",
        "          \n",
        "    v = torch_var(V)\n",
        "    v_mesh = torch_var(V_mesh)\n",
        "    \n",
        "    \n",
        "    pi_mesh = pi_net(v_mesh.view(-1, cfg.num_agents)).view(cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)   \n",
        "    pi_mesh = pi_mesh.mean(axis = -4)\n",
        "        \n",
        "    revenue = torch.zeros(cfg.num_agents).to(device)\n",
        "    ob_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ir_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ic_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(cfg.num_agents):\n",
        "                \n",
        "        #pi_interim: [Batch_size, Num_agents, Num_states, Num_signals], experiments assigned\n",
        "        pi_interim = pi_mesh[i] \n",
        "        \n",
        "        #x_interim: [Batch_size, Num_agents], Probability of taking correct actions\n",
        "        x_interim_all = compute_x_interim(pi_interim) \n",
        "        \n",
        "        # payoff_interim: x_i - \\alpha * \\sum_j != i x_j = (1 + \\alpha) x_i - (\\sum_j) x_j\n",
        "        payoff_interim = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all.sum(axis = -1)\n",
        "        \n",
        "        # Compute payments\n",
        "        pay_interim = compute_payments_from_fractions(v[i], payoff_interim, i)\n",
        "        \n",
        "        # Compute Revenue        \n",
        "        revenue[i] = pay_interim.mean()\n",
        "        \n",
        "        # Compute obedience violations\n",
        "        ob_viol[i] = compute_obedience_violations(x_interim_all[:, i], pi_interim[:, i]).mean()\n",
        "        \n",
        "        # Compute ir violation\n",
        "        ir_viol[i] = compute_ir_violation(v[i], payoff_interim, pay_interim).mean()\n",
        "        \n",
        "        # Compute ic violation: \n",
        "        # Uncomment this for random starts\n",
        "        # v_mis_init = torch_var(samplers[i](cfg.batch_size))\n",
        "        \n",
        "        # Warm-start with the best misreport computed using other minibatch vals\n",
        "        _, v_mis_init = compute_ic_violation_grid(v[i], payoff_interim, pay_interim)\n",
        "                \n",
        "        v_mis = compute_misreports_gd(v[i], v_mis_init, v_mesh[i], i, gd_lr = cfg.gd_lr, gd_iter = cfg.gd_iter)        \n",
        "        ic_viol[i] = compute_ic_viol(v[i], payoff_interim, pay_interim, v_mis, v_mesh[i], i).mean()\n",
        "    \n",
        "\n",
        "    rev_loss = -revenue.sum()\n",
        "    lagrangian = torch.dot(w_ob, ob_viol) + torch.dot(w_ir, ir_viol) + torch.dot(w_ic, ic_viol)\n",
        "    penalty = pho * ((ob_viol**2).sum() + (ir_viol**2).sum() + (ic_viol**2).sum())\n",
        "    \n",
        "    loss = rev_loss + penalty + lagrangian\n",
        "    if it % cfg.lag_up_iter == 0:\n",
        "        w_ob.data += pho * ob_viol.data\n",
        "        w_ic.data += pho * ic_viol.data\n",
        "        \n",
        "    if it % cfg.pho_up_iter == 0:\n",
        "        pho += pho_increment\n",
        "        \n",
        "    it += 1\n",
        "\n",
        "    ctrrev += revenue.sum()\n",
        "    ctrob += ob_viol.mean().item()\n",
        "    ctrir += ir_viol.mean().item()\n",
        "    ctric += ic_viol.mean().item()\n",
        "    loss.backward()\n",
        "    if iters % 1000 == 0 and iters != 0:\n",
        "      print(\"[Rev: %.4f], [OB Viol: %.4f], [IR Viol: %.4f], [IC Viol: %.4f]\"%(ctrrev/iters, ctrob/iters, ctrir/iters, ctric/iters))\n",
        "\n",
        "print(\"[Rev: %.4f], [OB Viol: %.4f], [IR Viol: %.4f], [IC Viol: %.4f]\"%(ctrrev/testitr, ctrob/testitr, ctrir/testitr, ctric/testitr))\n"
      ],
      "id": "84aa220f-a73f-40ed-9066-59a44231abe0"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python [conda env:.conda-data_markets]",
      "language": "python",
      "name": "conda-env-.conda-data_markets-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}