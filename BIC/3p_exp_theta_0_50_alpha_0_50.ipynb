{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "90a42f82-5981-4236-85c2-db2be1c59143"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.set_printoptions(sci_mode = False, precision = 4)"
      ],
      "id": "90a42f82-5981-4236-85c2-db2be1c59143"
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "18a2722d-fb74-4b97-a8b6-e8f3bbc1fe26"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "class HParams:\n",
        "    def __init__(self):\n",
        "        \n",
        "        # Problem params\n",
        "        self.num_agents = 3\n",
        "        self.num_states = 2\n",
        "        self.num_signals = 2\n",
        "        \n",
        "        self.theta = np.array([0.5, 0.5])\n",
        "        self.alpha = 0.5\n",
        "        \n",
        "        # Minibatch size\n",
        "        self.batch_size = 128\n",
        "        \n",
        "        # Number of samples for computing interim vals\n",
        "        self.num_samples = 512\n",
        "        \n",
        "        # Number of layer\n",
        "        self.R = 3\n",
        "        # Number of hidden units\n",
        "        self.K = 200\n",
        "        \n",
        "        # Data - Choose among exp, uniform, asym_uniform, irregular\n",
        "        self.distr_type = \"exp\"\n",
        "        \n",
        "        # Opt params\n",
        "        self.lr = 1e-3\n",
        "        \n",
        "        self.gd_lr = 5e-3\n",
        "        self.gd_iter = 8\n",
        "        \n",
        "        # Lagrangian params\n",
        "        \n",
        "        self.lag_ob_init = 10\n",
        "        self.lag_ir_init = 10\n",
        "        self.lag_ic_init = 10\n",
        "        \n",
        "        self.lag_up_iter = 100\n",
        "        \n",
        "        self.pho_init = 10\n",
        "        \n",
        "        self.pho_increment = 10\n",
        "        self.pho_up_iter = 100\n",
        "        \n",
        "        # Miscellaneous\n",
        "        self.seed = 0\n",
        "                  \n",
        "        self.max_iter = 30000 \n",
        "        self.print_iter = 1000\n",
        "                \n",
        "# Initialize config\n",
        "cfg = HParams()\n",
        "np.random.seed(cfg.seed)\n",
        "\n",
        "# Asserts\n",
        "# assert(cfg.num_agents == 2)\n",
        "device = \"cuda\"\n",
        "\n",
        "np.random.seed(cfg.seed)"
      ],
      "id": "18a2722d-fb74-4b97-a8b6-e8f3bbc1fe26"
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "43976218-80e7-4f72-a617-230515a16c5a"
      },
      "outputs": [],
      "source": [
        "def sampler_exp(idx, batch_size):\n",
        "    return np.random.exponential(scale = 1.0, size = (batch_size))\n",
        "\n",
        "def sampler_uniform(idx, batch_size):\n",
        "    return np.random.uniform(low = 0.0, high = 1.0, size = (batch_size))\n",
        "\n",
        "def sampler_asym_uniform(idx, batch_size):\n",
        "    return np.random.uniform(low = 0.0, high = idx + 1.0, size = (batch_size))\n",
        "\n",
        "def sampler_irr(idx, batch_size):    \n",
        "    sample_1 = np.random.uniform(low = 0.0, high = 3.0, size = (batch_size))\n",
        "    sample_2 = np.random.uniform(low = 3.0, high = 8.0, size = (batch_size))\n",
        "    mask = np.random.binomial(1, 0.75, (batch_size))\n",
        "    return (sample_1 * mask + sample_2 * (1 - mask))/10 \n",
        "\n",
        "if cfg.distr_type == \"exp\":\n",
        "    samplers = sampler_exp\n",
        "\n",
        "if cfg.distr_type == \"uniform\":\n",
        "    samplers = sampler_uniform\n",
        "        \n",
        "if cfg.distr_type == \"asym_uniform\":\n",
        "    samplers = sampler_asym_uniform\n",
        "    \n",
        "if cfg.distr_type == \"irregular\":\n",
        "    samplers = sampler_irr"
      ],
      "id": "43976218-80e7-4f72-a617-230515a16c5a"
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "f64e49ab-1323-4a63-93fb-2d1226ee7414"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "def torch_var(x): return torch.Tensor(x).to(device)\n",
        "def numpy_var(x): return x.detach().cpu().numpy()\n",
        "\n",
        "# Broadcasting into [n, 1] for easy multiplication\n",
        "theta = torch_var(cfg.theta)[:, None]"
      ],
      "id": "f64e49ab-1323-4a63-93fb-2d1226ee7414"
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "5522870a-54bb-40f9-801e-01d1a1a828b8"
      },
      "outputs": [],
      "source": [
        "# TODO: Initializations, Softmax temperatures\n",
        "\n",
        "class PiNet(nn.Module):      \n",
        "    def __init__(self, cfg):\n",
        "        super(PiNet, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        \n",
        "        num_agents = self.cfg.num_agents\n",
        "        num_states = self.cfg.num_states\n",
        "        num_signals = self.cfg.num_signals\n",
        "        \n",
        "        num_layers = self.cfg.R\n",
        "        num_hidden_nodes = self.cfg.K\n",
        "\n",
        "        self.pi = nn.ModuleList()\n",
        "        \n",
        "        # Input layer\n",
        "        self.pi.append(nn.Linear(num_agents, num_hidden_nodes))\n",
        "        self.pi.append(nn.LeakyReLU())\n",
        "        \n",
        "        # Hidden layers\n",
        "        for i in range(num_layers - 1):\n",
        "            self.pi.append(nn.Linear(num_hidden_nodes, num_hidden_nodes))\n",
        "            self.pi.append(nn.LeakyReLU())\n",
        "         \n",
        "        # Output layer\n",
        "        self.pi.append(nn.Linear(num_hidden_nodes, num_agents * num_states * num_signals))\n",
        "        \n",
        "        for m in self.pi:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "    def forward(self, v):\n",
        "        out = v\n",
        "        for module in self.pi: out = module(out)\n",
        "        out = out.view(-1, self.cfg.num_agents, self.cfg.num_states, self.cfg.num_signals)\n",
        "        return F.softmax(out, dim = -1)\n",
        "    \n",
        "    \n",
        "class PayNet(nn.Module):     \n",
        "    def __init__(self, cfg):\n",
        "        super(PayNet, self).__init__()\n",
        "        self.cfg = cfg        \n",
        "        num_layers = self.cfg.R\n",
        "        num_hidden_nodes = self.cfg.K\n",
        "\n",
        "        self.pay = nn.ModuleList()\n",
        "        \n",
        "        # Input layer\n",
        "        self.pay.append(nn.Linear(1, num_hidden_nodes))\n",
        "        self.pay.append(nn.LeakyReLU())\n",
        "        \n",
        "        # Hidden layers\n",
        "        for i in range(num_layers - 1):\n",
        "            self.pay.append(nn.Linear(num_hidden_nodes, num_hidden_nodes))\n",
        "            self.pay.append(nn.LeakyReLU())\n",
        "         \n",
        "        # Output layer\n",
        "        self.pay.append(nn.Linear(num_hidden_nodes, 1))\n",
        "        self.pay.append(nn.Sigmoid())\n",
        "        \n",
        "        for m in self.pay:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        \n",
        "    def forward(self, v):\n",
        "        out = v[:, None]\n",
        "        for module in self.pay: out = module(out)\n",
        "        return out.flatten()"
      ],
      "id": "5522870a-54bb-40f9-801e-01d1a1a828b8"
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "893b54b6-3543-4735-8e71-96981bd25678"
      },
      "outputs": [],
      "source": [
        "def compute_x_interim(pi_interim):\n",
        "    \"\"\"\n",
        "    Computes interim probability of taking the correct action \n",
        "    assuming obedience is satified\n",
        "    \n",
        "    Args:\n",
        "        pi_interim: [Batch_size, Num_States, Num_Signals]\n",
        "    Returns:\n",
        "        x_interim: [Batch_size]\n",
        "    \"\"\"\n",
        "    \n",
        "    return torch.diagonal(pi_interim * theta, offset = 0, dim1 = -2, dim2 = -1).sum(-1)\n",
        "\n",
        "def compute_x_deviation(pi_interim):\n",
        "    \"\"\"\n",
        "    Computes interim probability of taking the correct action \n",
        "    when obedience is not imposed    \n",
        "    Args:\n",
        "        pi_interim: [Batch_size, Num_States, Num_Signals]\n",
        "    Returns:\n",
        "        x_deviation: [Batch_size]\n",
        "    \"\"\"\n",
        "    \n",
        "    return torch.max(pi_interim * theta, axis = -2)[0].sum(-1)\n",
        "\n",
        "\n",
        "def compute_obedience_violations(x_interim, pi_interim):\n",
        "    \"\"\"\n",
        "    Computes obedience violation\n",
        "    Args:\n",
        "        x_inteirm: [Batch]\n",
        "    Returns:\n",
        "        ob_viol: [Batch]\n",
        "    \"\"\"\n",
        "\n",
        "    x_deviation = compute_x_deviation(pi_interim) \n",
        "    ob_viol = F.relu(x_deviation - x_interim)\n",
        "    return ob_viol"
      ],
      "id": "893b54b6-3543-4735-8e71-96981bd25678"
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "ca06b82e-4bc9-414b-9d72-40449fe5f3c2"
      },
      "outputs": [],
      "source": [
        "def compute_payments_from_fractions(v_i, payoff_interim, i):\n",
        "    \"\"\"\n",
        "    Computes interim payments from pay_frac\n",
        "    Args:\n",
        "        v_i: [Batch]\n",
        "        payoff_interim: [Batch]\n",
        "        pay_frac: [Batch]\n",
        "    Returns:\n",
        "        payment_interim: [Batch]\n",
        "    \"\"\"\n",
        "    \n",
        "    # Compute p_frac\n",
        "    pay_frac = pay_net[i](v_i)\n",
        "    \n",
        "    # Payoff if opting out\n",
        "    payoff_out = max(cfg.theta) - cfg.alpha\n",
        "    \n",
        "    \"\"\" \n",
        "    Pay <= Utility - Utility_out \n",
        "         = v_i * (payoff_interim - pay_out)     \n",
        "    \"\"\"\n",
        "    \n",
        "    payment_interim = v_i * (payoff_interim - payoff_out) * pay_frac\n",
        "    return payment_interim"
      ],
      "id": "ca06b82e-4bc9-414b-9d72-40449fe5f3c2"
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "f5151d96-0b8d-4712-93af-1502d7f2d23d"
      },
      "outputs": [],
      "source": [
        "def compute_ir_violation(v_i, payoff_interim, pay_interim):\n",
        "    \"\"\"\n",
        "    Computes IR violation\n",
        "    Args:\n",
        "        v_i: [Batch]\n",
        "        payoff_interim: [Batch]\n",
        "        pay_interim: [Batch]\n",
        "    Returns:\n",
        "        ir_viol: [Batch]\n",
        "    \"\"\"\n",
        "    \n",
        "    # Payoff if opting out\n",
        "    payoff_out = max(cfg.theta) - cfg.alpha    \n",
        "    ir_viol = F.relu( v_i * (payoff_out - payoff_interim) + pay_interim )\n",
        "    return ir_viol"
      ],
      "id": "f5151d96-0b8d-4712-93af-1502d7f2d23d"
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "8b93d976-9f4e-4e28-bde8-3edada270d5a"
      },
      "outputs": [],
      "source": [
        "def compute_ic_violation_grid(v_i, payoff_interim, pay_interim):\n",
        "    \"\"\"\n",
        "    Computes IC violation\n",
        "    Args:\n",
        "        v_i: [Batch]\n",
        "        payoff_interim: [Batch]\n",
        "        pay_interim: [Batch]\n",
        "    Returns:\n",
        "        ic_viol: [Batch]\n",
        "        v_mis: [Batch]\n",
        "\n",
        "    Compute v - payoff outer-product and subtract payment\n",
        "    Now we have a utility Mesh u_mesh whose i'th row j'th column has\n",
        "    the value v[i] * payoff[j] - pay[j]. This is exactly the utility of misreporting with b[i] = v[j]\n",
        "    The diagonal is the utility of truthful reporting. (as b[i] = v[i])\n",
        "    Compute ic_violation as max of misreporting - diagonal value.\n",
        "    \n",
        "    We can use this to warm-start GD: To be implemented\n",
        "    \"\"\"\n",
        "\n",
        "    u_mesh = v_i[:, None] * payoff_interim[None, :] - pay_interim[None, :]\n",
        "    \n",
        "    u_true = torch.diag(u_mesh)\n",
        "    u_mis, v_mis_idx =  u_mesh.max(axis = -1)\n",
        "    v_mis = v_i[v_mis_idx]\n",
        "    \n",
        "    ic_viol = F.relu(u_mis - u_true)\n",
        "    return ic_viol, v_mis.detach()"
      ],
      "id": "8b93d976-9f4e-4e28-bde8-3edada270d5a"
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "71c0ef64-7a0d-4cae-b56d-a4bfd7f355d9"
      },
      "outputs": [],
      "source": [
        "def compute_misreports_gd(v_i, v_mis_i, v_mesh_i, i, gd_lr = 5e-3, gd_iter = 100):\n",
        "    \n",
        "    # Autograd variables\n",
        "    v_mis_i = v_mis_i.detach().clone()\n",
        "    v_mis_i.requires_grad_(True)\n",
        "    \n",
        "    # Optimizer\n",
        "    opt = torch.optim.Adam([v_mis_i], gd_lr)\n",
        "    \n",
        "    for it in range(gd_iter):\n",
        "        \n",
        "        opt.zero_grad()        \n",
        "        u_mis = torch.zeros(cfg.num_agents).to(device)\n",
        "        \n",
        "        # Compose misreport - v_mesh [NA, BS, NS, NA]\n",
        "        v_mesh_mis = torch.cat((v_mesh_i[:, :, :i], v_mis_i[:, None, None].repeat(1, cfg.num_samples, 1), v_mesh_i[:, :, i + 1:]), axis = -1)\n",
        "        \n",
        "        pi_mesh_mis = pi_net(v_mesh_mis.view(-1, cfg.num_agents)).view(cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)\n",
        "        pi_interim_mis = pi_mesh_mis.mean(axis = -4)\n",
        "\n",
        "        #x_interim: [Batch_size, Num_agents], Probability of taking correct actions\n",
        "        x_interim_all_mis = compute_x_interim(pi_interim_mis) \n",
        "\n",
        "        # payoff_interim: x_i - \\alpha * \\sum_j != i x_j = (1 + \\alpha) x_i - (\\sum_j) x_j\n",
        "        payoff_interim_mis = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all_mis[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all_mis.sum(axis = -1)\n",
        "\n",
        "        # Compute payments\n",
        "        pay_interim_mis = compute_payments_from_fractions(v_mis_i, payoff_interim_mis, i)\n",
        "\n",
        "        u_mis = (v_i * payoff_interim_mis - pay_interim_mis).sum()\n",
        "            \n",
        "        u_mis_loss = (-u_mis.sum())\n",
        "        u_mis_loss.backward(inputs = v_mis_i)\n",
        "        opt.step()        \n",
        "        v_mis_i.data.clamp_(min = 0.0)\n",
        "        \n",
        "        \n",
        "    return v_mis_i.detach().clone()"
      ],
      "id": "71c0ef64-7a0d-4cae-b56d-a4bfd7f355d9"
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "77ac7f7d-88b2-4852-b12d-a240d94a4684"
      },
      "outputs": [],
      "source": [
        "def compute_ic_viol(v_i, payoff_interim, pay_interim, v_mis_i, v_mesh_i, i):\n",
        "    \n",
        "    v_mesh_mis = torch.cat((v_mesh_i[:, :, :i], v_mis_i[:, None, None].repeat(1, cfg.num_samples, 1), v_mesh_i[:, :, i + 1:]), axis = -1)\n",
        "    \n",
        "    # Compute interim pi_mis\n",
        "    pi_mesh_mis = pi_net(v_mesh_mis.view(-1, cfg.num_agents)).view(cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)\n",
        "    pi_interim_mis = pi_mesh_mis.mean(axis = -4)\n",
        "    \n",
        "    # Compute x_interim_mis, payoff_interim_mis, pay_interim_mis\n",
        "    x_interim_all_mis = compute_x_interim(pi_interim_mis)\n",
        "    payoff_interim_mis = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all_mis[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all_mis.sum(axis = -1)\n",
        "    pay_interim_mis = compute_payments_from_fractions(v_mis_i, payoff_interim_mis, i)\n",
        "    \n",
        "    # Compute u_mis\n",
        "    u_mis = (v_i * payoff_interim_mis - pay_interim_mis)\n",
        "    \n",
        "    # Compute u_true\n",
        "    u_true = v_i * payoff_interim - pay_interim\n",
        "    \n",
        "    # Compute ic_viol\n",
        "    ic_viol = F.relu(u_mis - u_true)\n",
        "    return ic_viol"
      ],
      "id": "77ac7f7d-88b2-4852-b12d-a240d94a4684"
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "a8e2a3e3-6c3e-4759-9169-9b86b3288396"
      },
      "outputs": [],
      "source": [
        "pi_net = PiNet(cfg).to(device)\n",
        "pay_net = [PayNet(cfg).to(device) for _ in range(cfg.num_agents)]\n",
        "# Keep in mind that if the distributions are asymetric, we need two different neural networks"
      ],
      "id": "a8e2a3e3-6c3e-4759-9169-9b86b3288396"
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "708c034f-8d53-4fa1-a6bb-c1b6f4afb75d"
      },
      "outputs": [],
      "source": [
        "lag_ob_init = cfg.lag_ob_init\n",
        "lag_ir_init = cfg.lag_ir_init\n",
        "lag_ic_init = cfg.lag_ic_init\n",
        "\n",
        "pho = cfg.pho_init\n",
        "pho_increment = cfg.pho_increment\n",
        "\n",
        "w_ob = torch.ones(cfg.num_agents).to(device) * lag_ob_init\n",
        "w_ir = torch.ones(cfg.num_agents).to(device) * lag_ir_init\n",
        "w_ic = torch.ones(cfg.num_agents).to(device) * lag_ic_init\n",
        "\n",
        "params = []\n",
        "params.extend(list(pi_net.parameters()))\n",
        "for i in range(cfg.num_agents):\n",
        "    params.extend(list(pay_net[i].parameters()))\n",
        "    \n",
        "opt = torch.optim.AdamW(params, lr=cfg.lr)\n",
        "\n",
        "it = 1"
      ],
      "id": "708c034f-8d53-4fa1-a6bb-c1b6f4afb75d"
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "27bda925-6cf4-405f-9a11-6411000417f3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "V_sample is a tensor of shape [num_agents, batch_size and num_samples].\n",
        "V_sample[i, :, :] contains 'num_samples' samples of agent i's valuation to be averaged over \n",
        "for the computation of interim values of the remaning agents. These samples are the same \n",
        "for every valuation profile in the minibatch. (i.e V[i, j, :] = V[i, k, :] )\n",
        "\"\"\"\n",
        "V_sample = np.zeros((cfg.num_agents, cfg.batch_size, cfg.num_samples))\n",
        "\n",
        "for i in range(cfg.num_agents):\n",
        "    V_sample[i] = np.tile(samplers(i, cfg.num_samples)[None, :], (cfg.batch_size, 1))"
      ],
      "id": "27bda925-6cf4-405f-9a11-6411000417f3"
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "100929ff-9541-4af8-ba94-750010e83e2b",
        "outputId": "6974befe-1491-47c8-b778-4113adf11858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iter: 1000], [Time Elapsed: 107.39s]\n",
            "[Rev: 0.6772], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0012]\n",
            "[Iter: 2000], [Time Elapsed: 214.90s]\n",
            "[Rev: 0.8314], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0014]\n",
            "[Iter: 3000], [Time Elapsed: 322.22s]\n",
            "[Rev: 0.8385], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0006]\n",
            "[Iter: 4000], [Time Elapsed: 429.61s]\n",
            "[Rev: 0.8552], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0005]\n",
            "[Iter: 5000], [Time Elapsed: 536.83s]\n",
            "[Rev: 0.8114], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0005]\n",
            "[Iter: 6000], [Time Elapsed: 644.19s]\n",
            "[Rev: 0.8021], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0005]\n",
            "[Iter: 7000], [Time Elapsed: 751.57s]\n",
            "[Rev: 0.7480], [OB Viol: 0.0001], [IR Viol: 0.0000], [IC Viol: 0.0003]\n",
            "[Iter: 8000], [Time Elapsed: 858.79s]\n",
            "[Rev: 0.8190], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0003]\n",
            "[Iter: 9000], [Time Elapsed: 966.01s]\n",
            "[Rev: 0.7844], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 10000], [Time Elapsed: 1073.18s]\n",
            "[Rev: 0.9061], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 11000], [Time Elapsed: 1180.18s]\n",
            "[Rev: 0.8309], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0003]\n",
            "[Iter: 12000], [Time Elapsed: 1287.07s]\n",
            "[Rev: 0.8512], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 13000], [Time Elapsed: 1394.05s]\n",
            "[Rev: 0.8652], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0003]\n",
            "[Iter: 14000], [Time Elapsed: 1501.05s]\n",
            "[Rev: 0.8052], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 15000], [Time Elapsed: 1607.96s]\n",
            "[Rev: 0.8481], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 16000], [Time Elapsed: 1714.98s]\n",
            "[Rev: 0.7995], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 17000], [Time Elapsed: 1821.76s]\n",
            "[Rev: 0.8852], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 18000], [Time Elapsed: 1928.74s]\n",
            "[Rev: 0.8880], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 19000], [Time Elapsed: 2035.67s]\n",
            "[Rev: 0.7604], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 20000], [Time Elapsed: 2142.45s]\n",
            "[Rev: 0.8018], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 21000], [Time Elapsed: 2249.25s]\n",
            "[Rev: 0.7138], [OB Viol: 0.0001], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 22000], [Time Elapsed: 2356.18s]\n",
            "[Rev: 0.8628], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 23000], [Time Elapsed: 2463.02s]\n",
            "[Rev: 0.8415], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 24000], [Time Elapsed: 2569.78s]\n",
            "[Rev: 0.7620], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 25000], [Time Elapsed: 2676.54s]\n",
            "[Rev: 0.8321], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 26000], [Time Elapsed: 2783.36s]\n",
            "[Rev: 0.8497], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 27000], [Time Elapsed: 2890.19s]\n",
            "[Rev: 0.8894], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 28000], [Time Elapsed: 2997.00s]\n",
            "[Rev: 0.7903], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 29000], [Time Elapsed: 3103.79s]\n",
            "[Rev: 0.7818], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0000]\n",
            "[Iter: 30000], [Time Elapsed: 3210.53s]\n",
            "[Rev: 0.9089], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "tic = time.time()\n",
        "                                  \n",
        "while it <= cfg.max_iter:\n",
        "    \n",
        "    \n",
        "    opt.zero_grad()\n",
        "    \n",
        "    \"\"\" \n",
        "    Construction of V_mesh:\n",
        "    V_mesh is of shape [num_agents, batch_size, num_samples, num_agents]\n",
        "    What's V_mesh[i, j, k, l]?\n",
        "    V[i, j] - has num_samples elements with the same valuation for agent - i\n",
        "    but with num_samples values from the V_sample array for other agents\n",
        "    \n",
        "    We use this for computation of payment, ic-viol, ob-viol for agent - i only\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    V = np.zeros((cfg.num_agents, cfg.batch_size))\n",
        "    V_mesh = np.zeros((cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents))\n",
        "\n",
        "\n",
        "    for i in range(cfg.num_agents):\n",
        "        V[i] = samplers(i, cfg.batch_size) \n",
        "        for j in range(cfg.num_agents):\n",
        "            if i == j:    \n",
        "                V_mesh[i, :, :, j] = np.tile(V[i][:, None], (1, cfg.num_samples))\n",
        "            else:\n",
        "                V_mesh[i, :, :, j] = V_sample[j]\n",
        "           \n",
        "    v = torch_var(V)\n",
        "    v_mesh = torch_var(V_mesh)\n",
        "    \n",
        "    \n",
        "    pi_mesh = pi_net(v_mesh.view(-1, cfg.num_agents)).view(cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)   \n",
        "    pi_mesh = pi_mesh.mean(axis = -4)\n",
        "        \n",
        "    revenue = torch.zeros(cfg.num_agents).to(device)\n",
        "    ob_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ir_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ic_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(cfg.num_agents):\n",
        "                \n",
        "        #pi_interim: [Batch_size, Num_agents, Num_states, Num_signals], experiments assigned\n",
        "        pi_interim = pi_mesh[i] \n",
        "        \n",
        "        #x_interim: [Batch_size, Num_agents], Probability of taking correct actions\n",
        "        x_interim_all = compute_x_interim(pi_interim) \n",
        "        \n",
        "        # payoff_interim: x_i - \\alpha * \\sum_j != i x_j = (1 + \\alpha) x_i - (\\sum_j) x_j\n",
        "        payoff_interim = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all.sum(axis = -1)\n",
        "        \n",
        "        # Compute payments\n",
        "        pay_interim = compute_payments_from_fractions(v[i], payoff_interim, i)\n",
        "        \n",
        "        # Compute Revenue        \n",
        "        revenue[i] = pay_interim.mean()\n",
        "        \n",
        "        # Compute obedience violations\n",
        "        ob_viol[i] = compute_obedience_violations(x_interim_all[:, i], pi_interim[:, i]).mean()\n",
        "        \n",
        "        # Compute ir violation\n",
        "        ir_viol[i] = compute_ir_violation(v[i], payoff_interim, pay_interim).mean()\n",
        "        \n",
        "        # Compute ic violation: \n",
        "        # Uncomment this for random starts\n",
        "        # v_mis_init = torch_var(samplers(i,cfg.batch_size))\n",
        "        \n",
        "        # Warm-start with the best misreport computed using other minibatch vals\n",
        "        _, v_mis_init = compute_ic_violation_grid(v[i], payoff_interim, pay_interim)\n",
        "                \n",
        "        v_mis = compute_misreports_gd(v[i], v_mis_init, v_mesh[i], i, gd_lr = cfg.gd_lr, gd_iter = cfg.gd_iter)        \n",
        "        ic_viol[i] = compute_ic_viol(v[i], payoff_interim, pay_interim, v_mis, v_mesh[i], i).mean()\n",
        "    \n",
        "\n",
        "    rev_loss = -revenue.sum()\n",
        "    lagrangian = torch.dot(w_ob, ob_viol) + torch.dot(w_ir, ir_viol) + torch.dot(w_ic, ic_viol)\n",
        "    penalty = pho * ((ob_viol**2).sum() + (ir_viol**2).sum() + (ic_viol**2).sum())\n",
        "    \n",
        "    loss = rev_loss + penalty + lagrangian\n",
        "    \n",
        "    loss.backward()   \n",
        "    opt.step()\n",
        "    \n",
        "    if it % cfg.print_iter == 0:\n",
        "        print(\"[Iter: %d], [Time Elapsed: %.2fs]\"%(it, time.time() - tic))\n",
        "        print(\"[Rev: %.4f], [OB Viol: %.4f], [IR Viol: %.4f], [IC Viol: %.4f]\"%(revenue.sum(), ob_viol.mean().item(), ir_viol.mean().item(), ic_viol.mean().item()))\n",
        "        \n",
        "    if it % cfg.lag_up_iter == 0:\n",
        "        w_ob.data += pho * ob_viol.data\n",
        "        w_ic.data += pho * ic_viol.data\n",
        "        \n",
        "    if it % cfg.pho_up_iter == 0:\n",
        "        pho += pho_increment\n",
        "        \n",
        "    it += 1"
      ],
      "id": "100929ff-9541-4af8-ba94-750010e83e2b"
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "2c22f1e6-7d2a-49b5-94fa-71802d903559",
        "outputId": "4af6eadf-61fc-4b37-fad1-55a332e56bab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import scipy.stats\n",
        "D = 81\n",
        "v1 = torch_var(np.linspace(0, 4, D))\n",
        "# v2 = torch_var(np.linspace(0, 0.8, D))\n",
        "s2 = torch_var(np.linspace(0, 8, D))\n",
        "v2 = s2/2\n",
        "v3 = s2.clone()/2\n",
        "v_mesh = torch.stack(torch.meshgrid(v1, v2, indexing = \"ij\"), axis = -1)\n",
        "v_mesh = torch.cat((v_mesh, v_mesh[:,:,1].reshape(D,D,1)),dim=-1)\n",
        "pi_mesh = torch.diagonal(pi_net(v_mesh.view(-1, 3)).view(D, D, cfg.num_agents, cfg.num_states, cfg.num_signals) * theta, 0, -2, -1).sum(-1)\n",
        "AM = numpy_var(pi_mesh)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(ncols = 1, nrows = 1, figsize=(5,4))\n",
        "\n",
        "img_1 = ax.imshow(AM[:, :, 0].transpose(1,0), extent=[0,4,0,8], vmin = 0.0,aspect = 0.5, vmax=1.0, cmap = 'YlOrRd', origin = \"lower\")\n",
        "plt.colorbar(img_1, ax = ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "# img_2 = ax[1].imshow(AM[:, :, 1].transpose(1,0), extent=[0,4,0,8], vmin = 0.0,aspect = 0.5, vmax=1.0, cmap = 'YlOrRd', origin = \"lower\")\n",
        "# plt.colorbar(img_2, ax = ax[1], fraction=0.046, pad=0.04)\n",
        "\n",
        "ax.plot([0, 0.91958675], [1.678347, 1.678347], color='black')\n",
        "ax.plot([0.91958675, 2.5],[1.678347, 8],color='black')\n",
        "\n",
        "ax.set_xlabel(\"$v_1$\")\n",
        "ax.set_ylabel(\"$v_{-1}$\")\n",
        "# ax[1].set_xlabel(\"$v_1$\")\n",
        "# ax[1].set_ylabel(\"$v_{-1}$\")\n",
        "\n",
        "fig.text(0.5, 1, r\"3agentExp, $\\alpha=%.2f, \\theta=%.2f$\"%(cfg.alpha, max(cfg.theta)), ha='center', size = 16)\n",
        "fig.tight_layout()"
      ],
      "id": "2c22f1e6-7d2a-49b5-94fa-71802d903559"
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iCJE-4A6x-TO",
        "outputId": "cca3ac74-7de3-4a8b-a07a-8adfe987dc8d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7169f820-acee-46fd-af58-7e8e611faa32\", \"new3p_exp_theta_0.50_alpha_0.50.pth\", 337535)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_953f5655-545d-470a-ad59-60efeb70dc36\", \"new3p_exp_theta_0.50_alpha_0.50p1.pth\", 327059)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5805afa6-af2a-46d5-b699-28ba026a9fbe\", \"new3p_exp_theta_0.50_alpha_0.50p2.pth\", 327059)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "torch.save(pi_net.state_dict(), 'new3p_exp_theta_0.50_alpha_0.50.pth')\n",
        "torch.save(pay_net[0].state_dict(), 'new3p_exp_theta_0.50_alpha_0.50p1.pth')\n",
        "torch.save(pay_net[1].state_dict(), 'new3p_exp_theta_0.50_alpha_0.50p2.pth')\n",
        "# # # download checkpoint file\n",
        "files.download('new3p_exp_theta_0.50_alpha_0.50.pth')\n",
        "files.download('new3p_exp_theta_0.50_alpha_0.50p1.pth')\n",
        "files.download('new3p_exp_theta_0.50_alpha_0.50p2.pth')\n",
        "# files.upload()\n",
        "# state_dict = torch.load('3p_exp_theta_0.50_alpha_0.50.pth')\n",
        "# state_dict_2 = torch.load('3p_exp_theta_0.50_alpha_0.50p1.pth')\n",
        "# state_dict_3 = torch.load('3p_exp_theta_0.50_alpha_0.50p2.pth')\n",
        "# pi_net.load_state_dict(state_dict)\n",
        "# pay_net[0].load_state_dict(state_dict_2)\n",
        "# pay_net[1].load_state_dict(state_dict_3)"
      ],
      "id": "iCJE-4A6x-TO"
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "84aa220f-a73f-40ed-9066-59a44231abe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037986d8-cb55-473b-ea49-e88710578a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Rev: 0.8353], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 0.8371], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 0.8369], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 0.8369], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 0.8361], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import gc\n",
        "tic = time.time()\n",
        "                              \n",
        "\n",
        "\"\"\" \n",
        "Construction of V_mesh:\n",
        "V_mesh is of shape [num_agents, batch_size, num_samples, num_agents]\n",
        "What's V_mesh[i, j, k, l]?\n",
        "V[i, j] - has num_samples elements with the same valuation for agent - i\n",
        "but with num_samples values from the V_sample array for other agents\n",
        "\n",
        "We use this for computation of payment, ic-viol, ob-viol for agent - i only\n",
        "\"\"\"\n",
        "ctrrev = 0\n",
        "ctrob = 0\n",
        "ctrir = 0\n",
        "ctric = 0\n",
        "testitr = 5000\n",
        "for iters in range(testitr):\n",
        "    opt.zero_grad()\n",
        "  \n",
        "    \"\"\" \n",
        "    Construction of V_mesh:\n",
        "    V_mesh is of shape [num_agents, batch_size, num_samples, num_agents]\n",
        "    What's V_mesh[i, j, k, l]?\n",
        "    V[i, j] - has num_samples elements with the same valuation for agent - i\n",
        "    but with num_samples values from the V_sample array for other agents\n",
        "    \n",
        "    We use this for computation of payment, ic-viol, ob-viol for agent - i only\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    V = np.zeros((cfg.num_agents, cfg.batch_size))\n",
        "    V_mesh = np.zeros((cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents))\n",
        "\n",
        "\n",
        "    for i in range(cfg.num_agents):\n",
        "        V[i] = samplers(i, cfg.batch_size)    \n",
        "        for j in range(cfg.num_agents):\n",
        "            if i == j:    \n",
        "                V_mesh[i, :, :, j] = np.tile(V[i][:, None], (1, cfg.num_samples))\n",
        "            else:\n",
        "                V_mesh[i, :, :, j] = V_sample[j]\n",
        "          \n",
        "    v = torch_var(V)\n",
        "    v_mesh = torch_var(V_mesh)\n",
        "    \n",
        "    \n",
        "    pi_mesh = pi_net(v_mesh.view(-1, cfg.num_agents)).view(cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)   \n",
        "    pi_mesh = pi_mesh.mean(axis = -4)\n",
        "        \n",
        "    revenue = torch.zeros(cfg.num_agents).to(device)\n",
        "    ob_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ir_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ic_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(cfg.num_agents):\n",
        "                \n",
        "        #pi_interim: [Batch_size, Num_agents, Num_states, Num_signals], experiments assigned\n",
        "        pi_interim = pi_mesh[i] \n",
        "        \n",
        "        #x_interim: [Batch_size, Num_agents], Probability of taking correct actions\n",
        "        x_interim_all = compute_x_interim(pi_interim) \n",
        "        \n",
        "        # payoff_interim: x_i - \\alpha * \\sum_j != i x_j = (1 + \\alpha) x_i - (\\sum_j) x_j\n",
        "        payoff_interim = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all.sum(axis = -1)\n",
        "        \n",
        "        # Compute payments\n",
        "        pay_interim = compute_payments_from_fractions(v[i], payoff_interim, i)\n",
        "        \n",
        "        # Compute Revenue        \n",
        "        revenue[i] = pay_interim.mean()\n",
        "        \n",
        "        # Compute obedience violations\n",
        "        ob_viol[i] = compute_obedience_violations(x_interim_all[:, i], pi_interim[:, i]).mean()\n",
        "        \n",
        "        # Compute ir violation\n",
        "        ir_viol[i] = compute_ir_violation(v[i], payoff_interim, pay_interim).mean()\n",
        "        \n",
        "        # Compute ic violation: \n",
        "        # Uncomment this for random starts\n",
        "        # v_mis_init = torch_var(samplers[i](cfg.batch_size))\n",
        "        \n",
        "        # Warm-start with the best misreport computed using other minibatch vals\n",
        "        _, v_mis_init = compute_ic_violation_grid(v[i], payoff_interim, pay_interim)\n",
        "                \n",
        "        v_mis = compute_misreports_gd(v[i], v_mis_init, v_mesh[i], i, gd_lr = cfg.gd_lr, gd_iter = cfg.gd_iter)        \n",
        "        ic_viol[i] = compute_ic_viol(v[i], payoff_interim, pay_interim, v_mis, v_mesh[i], i).mean()\n",
        "    \n",
        "\n",
        "    rev_loss = -revenue.sum()\n",
        "    lagrangian = torch.dot(w_ob, ob_viol) + torch.dot(w_ir, ir_viol) + torch.dot(w_ic, ic_viol)\n",
        "    penalty = pho * ((ob_viol**2).sum() + (ir_viol**2).sum() + (ic_viol**2).sum())\n",
        "    \n",
        "    loss = rev_loss + penalty + lagrangian\n",
        "    if it % cfg.lag_up_iter == 0:\n",
        "        w_ob.data += pho * ob_viol.data\n",
        "        w_ic.data += pho * ic_viol.data\n",
        "        \n",
        "    if it % cfg.pho_up_iter == 0:\n",
        "        pho += pho_increment\n",
        "        \n",
        "    it += 1\n",
        "\n",
        "    ctrrev += revenue.sum()\n",
        "    ctrob += ob_viol.mean().item()\n",
        "    ctrir += ir_viol.mean().item()\n",
        "    ctric += ic_viol.mean().item()\n",
        "    loss.backward()\n",
        "    if iters % 1000 == 0 and iters != 0:\n",
        "      print(\"[Rev: %.4f], [OB Viol: %.4f], [IR Viol: %.4f], [IC Viol: %.4f]\"%(ctrrev/iters, ctrob/iters, ctrir/iters, ctric/iters))\n",
        "\n",
        "print(\"[Rev: %.4f], [OB Viol: %.4f], [IR Viol: %.4f], [IC Viol: %.4f]\"%(ctrrev/testitr, ctrob/testitr, ctrir/testitr, ctric/testitr))\n"
      ],
      "id": "84aa220f-a73f-40ed-9066-59a44231abe0"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python [conda env:.conda-data_markets]",
      "language": "python",
      "name": "conda-env-.conda-data_markets-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}