{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a42f82-5981-4236-85c2-db2be1c59143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_printoptions(sci_mode = False, precision = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2722d-fb74-4b97-a8b6-e8f3bbc1fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "class HParams:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Problem params\n",
    "        self.num_agents = 2\n",
    "        self.num_states = 2\n",
    "        self.num_signals = 2\n",
    "        \n",
    "        self.theta = np.array([0.75, 0.25])\n",
    "        self.alpha = 0.5\n",
    "        \n",
    "        # Minibatch size\n",
    "        self.batch_size = 1024\n",
    "        self.num_misreports = 100\n",
    "        \n",
    "        \n",
    "        # Number of layer\n",
    "        self.R = 3\n",
    "        # Number of hidden units\n",
    "        self.K = 200\n",
    "        \n",
    "        # Data - Choose among exp, uniform, assymetric_uniform, irregular\n",
    "        self.distr_type = \"exp\"\n",
    "        \n",
    "        # Opt params\n",
    "        self.lr = 1e-3\n",
    "        \n",
    "        self.gd_lr = 5e-3\n",
    "        self.gd_iter = 0\n",
    "        \n",
    "        self.temp = 0.1\n",
    "        \n",
    "        # Lagrangian params\n",
    "        self.lag_ic_init = 1\n",
    "        self.lag_up_iter = 100\n",
    "        \n",
    "        self.pho_init = 1\n",
    "        self.pho_increment = 10\n",
    "        self.pho_up_iter = 1000\n",
    "        \n",
    "        # Miscellaneous\n",
    "        self.seed = 0\n",
    "                  \n",
    "        self.max_iter = 20000 \n",
    "        self.print_iter = 1000\n",
    "        \n",
    "        \n",
    "        \"\"\" Test params \"\"\"\n",
    "        self.test_batch_size = 1024\n",
    "        self.test_num_misreports = 100\n",
    "        self.test_num_batches = 200\n",
    "        self.test_gd_lr =  5e-3\n",
    "        self.test_gd_iter = 100\n",
    "        \n",
    "                \n",
    "# Initialize config\n",
    "cfg = HParams()\n",
    "np.random.seed(cfg.seed)\n",
    "\n",
    "# Asserts\n",
    "assert(cfg.num_agents == 2)\n",
    "device = \"cuda\"\n",
    "\n",
    "np.random.seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1901142-ee4b-43ff-98f4-e873b1c52e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(batch_size):\n",
    "    shape = (batch_size, cfg.num_agents)\n",
    "    return np.random.rand(*shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e49ab-1323-4a63-93fb-2d1226ee7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def torch_var(x): return torch.Tensor(x).to(device)\n",
    "def numpy_var(x): return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522870a-54bb-40f9-801e-01d1a1a828b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initializations, Softmax temperatures\n",
    "\n",
    "class ActionNet(nn.Module):      \n",
    "    def __init__(self, cfg):\n",
    "        super(ActionNet, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        num_agents = self.cfg.num_agents\n",
    "        num_states = self.cfg.num_states\n",
    "        num_signals = self.cfg.num_signals\n",
    "        \n",
    "        num_layers = self.cfg.R\n",
    "        num_hidden_nodes = self.cfg.K\n",
    "        \n",
    "        self.theta = torch_var(self.cfg.theta)[:, None]\n",
    "        self.temp = torch_var([self.cfg.temp])\n",
    "\n",
    "        self.pi = nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        m = nn.Linear(num_agents, num_hidden_nodes)\n",
    "        nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        self.pi.append(m)\n",
    "        self.pi.append(nn.LeakyReLU())\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(num_layers - 1):\n",
    "            m = nn.Linear(num_hidden_nodes, num_hidden_nodes)\n",
    "            nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            self.pi.append(m)\n",
    "            self.pi.append(nn.LeakyReLU())\n",
    "         \n",
    "        # Output layer\n",
    "        m = nn.Linear(num_hidden_nodes, num_agents * num_states * num_signals)\n",
    "        nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        self.pi.append(m)\n",
    "\n",
    "    def forward(self, v):\n",
    "        out = v\n",
    "        for module in self.pi: out = module(out)\n",
    "        out = out.view(-1, self.cfg.num_agents, self.cfg.num_states, self.cfg.num_signals)\n",
    "        pi =  F.softmax(out / self.temp, dim = -1)\n",
    "        return torch.max(pi * self.theta, axis = -2)[0].sum(axis = -1)\n",
    "    \n",
    "    \n",
    "class PayNet(nn.Module):     \n",
    "    def __init__(self, cfg):\n",
    "        super(PayNet, self).__init__()\n",
    "        self.cfg = cfg                \n",
    "        num_agents = self.cfg.num_agents\n",
    "        num_layers = self.cfg.R\n",
    "        num_hidden_nodes = self.cfg.K\n",
    "\n",
    "        self.pay = nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        m = nn.Linear(num_agents, num_hidden_nodes)\n",
    "        nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        self.pay.append(m)\n",
    "        self.pay.append(nn.LeakyReLU())\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(num_layers - 1):\n",
    "            m = nn.Linear(num_hidden_nodes, num_hidden_nodes)\n",
    "            nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            self.pay.append(m)\n",
    "            self.pay.append(nn.LeakyReLU())\n",
    "\n",
    "         \n",
    "        # Output layer\n",
    "        m = nn.Linear(num_hidden_nodes, num_agents)\n",
    "        nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        self.pay.append(m)\n",
    "                \n",
    "    def forward(self, v):\n",
    "        out = v\n",
    "        for module in self.pay: out = module(out)\n",
    "        return v * torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cc0d5-2286-4aaa-9740-1f64a1aa3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_utility(x):\n",
    "    u = (1 + cfg.alpha) * x - cfg.alpha * x.sum(axis = -1, keepdim=True)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b54b6-3543-4735-8e71-96981bd25678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_payments(x, p_frac):\n",
    "    \"\"\"\n",
    "    Computes payments\n",
    "    Args:\n",
    "        x: [Batch, num_agents]\n",
    "    Returns:\n",
    "        pay: [Batch, num_agents]\n",
    "    \"\"\"\n",
    "    \n",
    "    u_in = compute_utility(x)\n",
    "    u_out = (max(cfg.theta) - cfg.alpha)  \n",
    "    return p_frac * (u_in - u_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0b123-8149-4e9f-8f5d-8965ca6fba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_misreports_samples(b, v, u):\n",
    "    \n",
    "    ic_viol = torch.zeros(cfg.num_agents).to(device)\n",
    "    \n",
    "    batch_size, num_misreports = b.shape[0], b.shape[1]\n",
    "    v_mis = v[:, None, :].repeat(1, num_misreports, 1)\n",
    "    \n",
    "    \n",
    "    best_b = torch.zeros(batch_size, cfg.num_agents).to(device)\n",
    "    \n",
    "    # Compute IC violation for each agent\n",
    "    for i in range(cfg.num_agents):  \n",
    "        \n",
    "        # Compose misreport of shape: [batch_size, num_misreports, num_agents]\n",
    "        b_mis = torch.cat((v_mis[:, :, :i], b[:, :, i: i + 1], v_mis[:, :, i + 1:]), axis = -1)\n",
    "        b_mis = b_mis.view(-1, cfg.num_agents)\n",
    "        \n",
    "        # Compute action_mis, pay_mis\n",
    "        x_mis = action_net(b_mis)\n",
    "        p_mis = compute_payments(x_mis, pay_net(b_mis))\n",
    "        \n",
    "        \n",
    "        # BS x NM: 12800\n",
    "        w_mis = (1 + cfg.alpha) * x_mis[:, i] - cfg.alpha * x_mis.sum(axis = -1)\n",
    "        u_mis = v_mis[:, :, i].reshape(-1) * w_mis - p_mis[:, i]\n",
    "        u_mis = u_mis.reshape(-1, num_misreports)\n",
    "\n",
    "        u_mis, b_mis_idx = u_mis.max(axis = -1)\n",
    "        best_b[:, i] = b[:, :, i][torch.arange(b.shape[0]), b_mis_idx]\n",
    "        ic_viol[i] += F.relu(u_mis - u[:, i]).mean()\n",
    "        \n",
    "        \n",
    "    return ic_viol, best_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccfcb25-11fa-4804-8dc2-e99cf5fe8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_misreports_gd(b_var, v, gd_lr = 5e-3, gd_iter = 100):\n",
    "    \n",
    "    # Autograd variables\n",
    "    b_var = b_var.detach().clone()\n",
    "    b_var.requires_grad_(True)\n",
    "    \n",
    "    # Optimizer\n",
    "    opt = torch.optim.Adam([b_var], lr = gd_lr)\n",
    "    \n",
    "    for it in range(gd_iter):\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        u_mis = torch.zeros(cfg.num_agents).to(device)\n",
    "        \n",
    "        for i in range(cfg.num_agents):\n",
    "            \n",
    "            b_mis = torch.cat((v[:, :i], b_var[:, i: i + 1], v[:, i + 1:]), axis = -1)\n",
    "            \n",
    "            x_mis = action_net(b_mis)\n",
    "            p_mis = compute_payments(x_mis, pay_net(b_mis))\n",
    "            \n",
    "            w_mis = (1 + cfg.alpha) * x_mis[:, i] - cfg.alpha * x_mis.sum(axis = -1)\n",
    "            u_mis[i] = (v[:, i] * w_mis - p_mis[:, i]).sum()\n",
    "\n",
    "            \n",
    "        u_mis_loss = (-u_mis.sum())\n",
    "        u_mis_loss.backward(inputs = b_var)\n",
    "        opt.step()        \n",
    "        b_var.data.clamp_(min = 0.0, max = 1.0)\n",
    "        \n",
    "        \n",
    "    return b_var.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41e16b-8245-4022-82c5-5f1c4a5a7c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ic_viol(b_var, v, u):\n",
    "    \n",
    "    ic_viol = torch.zeros(cfg.num_agents).to(device)\n",
    "    \n",
    "    # Compute IC violation for each agent\n",
    "    for i in range(cfg.num_agents):  \n",
    "        \n",
    "        # Compose misreport of shape: [batch_size, num_misreports, num_agents]\n",
    "        b_mis = torch.cat((v[:, :i], b_var[:, i: i + 1], v[:, i + 1:]), axis = -1)\n",
    "        \n",
    "        # Compute action_mis, pay_mis\n",
    "        x_mis = action_net(b_mis)\n",
    "        p_mis = compute_payments(x_mis, pay_net(b_mis))\n",
    "        \n",
    "        w_mis = (1 + cfg.alpha) * x_mis[:, i] - cfg.alpha * x_mis.sum(axis = -1)\n",
    "        u_mis = v[:, i] * w_mis - p_mis[:, i]\n",
    "        ic_viol[i] += F.relu((u_mis - u[:, i])/(v[:, i] + 1e-8)).mean()\n",
    "        \n",
    "    return ic_viol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2a3e3-6c3e-4759-9169-9b86b3288396",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_net = ActionNet(cfg).to(device)\n",
    "pay_net = PayNet(cfg).to(device)\n",
    "# Keep in mind that if the distributions are asymetric, we need two different neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c034f-8d53-4fa1-a6bb-c1b6f4afb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_ic_init = cfg.lag_ic_init\n",
    "w_ic = torch.ones(cfg.num_agents).to(device) * lag_ic_init\n",
    "\n",
    "pho = cfg.pho_init\n",
    "pho_increment = cfg.pho_increment\n",
    "\n",
    "opt = torch.optim.AdamW(list(action_net.parameters()) + list(pay_net.parameters()), lr=cfg.lr)\n",
    "\n",
    "it = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100929ff-9541-4af8-ba94-750010e83e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "                                  \n",
    "while it <= cfg.max_iter:\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # Get batch\n",
    "    V = sample_batch(cfg.batch_size)\n",
    "    v = torch_var(V)\n",
    "    \n",
    "    x = action_net(v)\n",
    "    pay = compute_payments(x, pay_net(v))\n",
    "    \n",
    "    # Compute Revenue\n",
    "    revenue = pay.sum(axis = -1).mean()\n",
    "    \n",
    "    # Compute utility\n",
    "    u = v * compute_utility(x) - pay\n",
    "    \n",
    "    # Compute IC-Violation\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        b = torch_var(sample_batch(cfg.batch_size * cfg.num_misreports).reshape(cfg.batch_size, cfg.num_misreports, -1))\n",
    "        _, b_var = compute_misreports_samples(b, v, u)\n",
    "        \n",
    "    b_var = compute_misreports_gd(b_var, v, gd_lr = cfg.gd_lr, gd_iter = cfg.gd_iter)\n",
    "    ic_viol = compute_ic_viol(b_var, v, u)\n",
    "     \n",
    "    # Compute Loss\n",
    "    rev_loss = -revenue\n",
    "    lagrangian = torch.dot(w_ic, ic_viol)\n",
    "    penalty = pho * (ic_viol**2).sum()\n",
    "    loss = rev_loss + penalty + lagrangian\n",
    "    \n",
    "    # GD Step\n",
    "    loss.backward()   \n",
    "    opt.step()\n",
    "    \n",
    "    if it % cfg.print_iter == 0:\n",
    "        print(\"[Iter: %d], [Time Elapsed: %.2fs]\"%(it, time.time() - tic))\n",
    "        print(\"[Rev: %.4f], [IC Viol: %.4f]\"%(revenue.sum(), ic_viol.mean().item()))\n",
    "        \n",
    "    if it % cfg.lag_up_iter == 0:\n",
    "        w_ic.data += pho * ic_viol.data\n",
    "        \n",
    "    if it % cfg.pho_up_iter == 0:\n",
    "        pho += pho_increment\n",
    "        \n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f254e0-3213-4118-9439-48362ac8e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal\n",
    "def phi(v): return 2*v - 1\n",
    "def phi_inv(v): return (v-1)/2 + 1\n",
    "\n",
    "def compute_opt_payment(V): \n",
    "    theta = max(cfg.theta)\n",
    "    P = np.zeros(V.shape)\n",
    "    for i in range(len(V)):\n",
    "        v1, v2 = V[i]\n",
    "        r1 = max(0, phi_inv(1/cfg.alpha * phi(v2)))\n",
    "        r2 = max(0, phi_inv(cfg.alpha * phi(v2)))\n",
    "        if v2 <= phi_inv(0):\n",
    "            P[i, 0] += (r2 * (v1 >= r2) + r1 * cfg.alpha * (v1 >= r1)) * (1 - theta)\n",
    "        else:\n",
    "            P[i, 0] += (r1 * cfg.alpha * (v1 >= r1) + r2 * (v1 >= r2)) * (1 - theta)\n",
    "            \n",
    "        v2, v1 = V[i]\n",
    "        r1 = max(0, phi_inv(1/cfg.alpha * phi(v2)))\n",
    "        r2 = max(0, phi_inv(cfg.alpha * phi(v2)))\n",
    "        if v2 <= phi_inv(0):\n",
    "            P[i, 1] += (r2 * (v1 >= r2) + r1 * cfg.alpha * (v1 >= r1)) * (1 - theta)\n",
    "        else:\n",
    "            P[i, 1] += (r1 * cfg.alpha * (v1 >= r1) + r2 * (v1 >= r2)) * (1 - theta)\n",
    "    return P\n",
    "\n",
    "with torch.no_grad():\n",
    "    REV = 0\n",
    "    IC_viol = 0   \n",
    "    OPT_REV = 0\n",
    "    \n",
    "    for i in range(cfg.test_num_batches):\n",
    "        \n",
    "        V = sample_batch(cfg.test_batch_size)\n",
    "        v = torch_var(V)\n",
    "        \n",
    "        x = action_net(v)\n",
    "        pay = compute_payments(x, pay_net(v))\n",
    "        u = v * ((1 + cfg.alpha) * x - cfg.alpha * x.sum(axis = -1, keepdim=True)) - pay\n",
    "        \n",
    "        b = torch_var(sample_batch(cfg.test_batch_size * cfg.test_num_misreports).reshape(cfg.test_batch_size, cfg.test_num_misreports, -1))\n",
    "        _, b_var = compute_misreports_samples(b, v, u)\n",
    "    \n",
    "    \n",
    "        #with torch.set_grad_enabled(True):\n",
    "        #    b_var = compute_misreports_gd(b_var, v, gd_lr = cfg.test_gd_lr, gd_iter = cfg.test_gd_iter)\n",
    "    \n",
    "        \n",
    "        ic_viol = compute_ic_viol(b_var, v, u)\n",
    "    \n",
    "\n",
    "        revenue = pay.sum(-1).mean()   \n",
    "        \n",
    "        REV += revenue.item()\n",
    "        IC_viol += ic_viol.mean().item()\n",
    "        OPT_REV += compute_opt_payment(V).sum(-1).mean()\n",
    "        \n",
    "    OPT_REV = OPT_REV/cfg.test_num_batches\n",
    "    REV = REV/cfg.test_num_batches\n",
    "    IC_viol = IC_viol/cfg.test_num_batches\n",
    "    \n",
    "print(\"Rev: %.4f, IC_viol: %.4f, OPT_REV: %.4f\"%(REV, IC_viol, OPT_REV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c22f1e6-7d2a-49b5-94fa-71802d903559",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch_var(np.linspace(0, 1, 201))\n",
    "v_mesh = torch.stack(torch.meshgrid(v, v, indexing = \"ij\"), axis = -1)\n",
    "x_mesh = action_net(v_mesh.view(-1, 2)).view(201, 201, 2)\n",
    "AM = numpy_var(x_mesh)\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 2, nrows = 1, figsize=(9,4))\n",
    "\n",
    "img_1 = ax[0].imshow(AM[:, :, 0].transpose(1,0), extent=[0,1,0,1], vmin = 0.0, vmax=1.0, cmap = 'YlOrRd', origin = \"lower\")\n",
    "plt.colorbar(img_1, ax = ax[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "img_2 = ax[1].imshow(AM[:, :, 1].transpose(1,0), extent=[0,1,0,1], vmin = 0.0, vmax=1.0, cmap = 'YlOrRd', origin = \"lower\")\n",
    "plt.colorbar(img_2, ax = ax[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "\n",
    "\n",
    "ax[0].plot([0.25, 0.75],[0, 1],color='black')\n",
    "ax[1].plot([0, 1], [0.25, 0.75], color='black')\n",
    "\n",
    "ax[0].set_xlabel(\"$v_1$\")\n",
    "ax[0].set_ylabel(\"$v_2$\")\n",
    "ax[1].set_xlabel(\"$v_1$\")\n",
    "ax[1].set_ylabel(\"$v_2$\")\n",
    "\n",
    "fig.text(0.5, 1, r\"Uniform, $\\alpha=%.2f, \\theta=%.2f$\"%(cfg.alpha, max(cfg.theta)), ha='center', size = 16)\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"DSIC_U_theta_%.2f_alpha_%.2f.pdf\"%(max(cfg.theta), cfg.alpha), bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-data_markets]",
   "language": "python",
   "name": "conda-env-.conda-data_markets-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
