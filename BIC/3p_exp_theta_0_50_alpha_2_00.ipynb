{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "90a42f82-5981-4236-85c2-db2be1c59143"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.set_printoptions(sci_mode = False, precision = 4)"
      ],
      "id": "90a42f82-5981-4236-85c2-db2be1c59143"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "18a2722d-fb74-4b97-a8b6-e8f3bbc1fe26"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "class HParams:\n",
        "    def __init__(self):\n",
        "        \n",
        "        # Problem params\n",
        "        self.num_agents = 3\n",
        "        self.num_states = 2\n",
        "        self.num_signals = 2\n",
        "        \n",
        "        self.theta = np.array([0.5, 0.5])\n",
        "        self.alpha = 2\n",
        "        \n",
        "        # Minibatch size\n",
        "        self.batch_size = 128\n",
        "        \n",
        "        # Number of samples for computing interim vals\n",
        "        self.num_samples = 512\n",
        "        \n",
        "        # Number of layer\n",
        "        self.R = 3\n",
        "        # Number of hidden units\n",
        "        self.K = 200\n",
        "        \n",
        "        # Data - Choose among exp, uniform, asym_uniform, irregular\n",
        "        self.distr_type = \"exp\"\n",
        "        \n",
        "        # Opt params\n",
        "        self.lr = 1e-3\n",
        "        \n",
        "        self.gd_lr = 5e-3\n",
        "        self.gd_iter = 8\n",
        "        \n",
        "        # Lagrangian params\n",
        "        \n",
        "        self.lag_ob_init = 10\n",
        "        self.lag_ir_init = 10\n",
        "        self.lag_ic_init = 10\n",
        "        \n",
        "        self.lag_up_iter = 100\n",
        "        \n",
        "        self.pho_init = 10\n",
        "        \n",
        "        self.pho_increment = 10\n",
        "        self.pho_up_iter = 100\n",
        "        \n",
        "        # Miscellaneous\n",
        "        self.seed = 0\n",
        "                  \n",
        "        self.max_iter = 30000 \n",
        "        self.print_iter = 1000\n",
        "                \n",
        "# Initialize config\n",
        "cfg = HParams()\n",
        "np.random.seed(cfg.seed)\n",
        "\n",
        "# Asserts\n",
        "# assert(cfg.num_agents == 2)\n",
        "device = \"cuda\"\n",
        "\n",
        "np.random.seed(cfg.seed)"
      ],
      "id": "18a2722d-fb74-4b97-a8b6-e8f3bbc1fe26"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "43976218-80e7-4f72-a617-230515a16c5a"
      },
      "outputs": [],
      "source": [
        "def sampler_exp(idx, batch_size):\n",
        "    return np.random.exponential(scale = 1.0, size = (batch_size))\n",
        "\n",
        "def sampler_uniform(idx, batch_size):\n",
        "    return np.random.uniform(low = 0.0, high = 1.0, size = (batch_size))\n",
        "\n",
        "def sampler_asym_uniform(idx, batch_size):\n",
        "    return np.random.uniform(low = 0.0, high = idx + 1.0, size = (batch_size))\n",
        "\n",
        "def sampler_irr(idx, batch_size):    \n",
        "    sample_1 = np.random.uniform(low = 0.0, high = 3.0, size = (batch_size))\n",
        "    sample_2 = np.random.uniform(low = 3.0, high = 8.0, size = (batch_size))\n",
        "    mask = np.random.binomial(1, 0.75, (batch_size))\n",
        "    return (sample_1 * mask + sample_2 * (1 - mask))/10 \n",
        "\n",
        "if cfg.distr_type == \"exp\":\n",
        "    samplers = sampler_exp\n",
        "\n",
        "if cfg.distr_type == \"uniform\":\n",
        "    samplers = sampler_uniform\n",
        "        \n",
        "if cfg.distr_type == \"asym_uniform\":\n",
        "    samplers = sampler_asym_uniform\n",
        "    \n",
        "if cfg.distr_type == \"irregular\":\n",
        "    samplers = sampler_irr"
      ],
      "id": "43976218-80e7-4f72-a617-230515a16c5a"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "f64e49ab-1323-4a63-93fb-2d1226ee7414"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "def torch_var(x): return torch.Tensor(x).to(device)\n",
        "def numpy_var(x): return x.detach().cpu().numpy()\n",
        "\n",
        "# Broadcasting into [n, 1] for easy multiplication\n",
        "theta = torch_var(cfg.theta)[:, None]"
      ],
      "id": "f64e49ab-1323-4a63-93fb-2d1226ee7414"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "5522870a-54bb-40f9-801e-01d1a1a828b8"
      },
      "outputs": [],
      "source": [
        "# TODO: Initializations, Softmax temperatures\n",
        "\n",
        "class PiNet(nn.Module):      \n",
        "    def __init__(self, cfg):\n",
        "        super(PiNet, self).__init__()\n",
        "        self.cfg = cfg\n",
        "        \n",
        "        num_agents = self.cfg.num_agents\n",
        "        num_states = self.cfg.num_states\n",
        "        num_signals = self.cfg.num_signals\n",
        "        \n",
        "        num_layers = self.cfg.R\n",
        "        num_hidden_nodes = self.cfg.K\n",
        "\n",
        "        self.pi = nn.ModuleList()\n",
        "        \n",
        "        # Input layer\n",
        "        self.pi.append(nn.Linear(num_agents, num_hidden_nodes))\n",
        "        self.pi.append(nn.LeakyReLU())\n",
        "        \n",
        "        # Hidden layers\n",
        "        for i in range(num_layers - 1):\n",
        "            self.pi.append(nn.Linear(num_hidden_nodes, num_hidden_nodes))\n",
        "            self.pi.append(nn.LeakyReLU())\n",
        "         \n",
        "        # Output layer\n",
        "        self.pi.append(nn.Linear(num_hidden_nodes, num_agents * num_states * num_signals))\n",
        "        \n",
        "        for m in self.pi:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "    def forward(self, v):\n",
        "        out = v\n",
        "        for module in self.pi: out = module(out)\n",
        "        out = out.view(-1, self.cfg.num_agents, self.cfg.num_states, self.cfg.num_signals)\n",
        "        return F.softmax(out, dim = -1)\n",
        "    \n",
        "    \n",
        "class PayNet(nn.Module):     \n",
        "    def __init__(self, cfg):\n",
        "        super(PayNet, self).__init__()\n",
        "        self.cfg = cfg        \n",
        "        num_layers = self.cfg.R\n",
        "        num_hidden_nodes = self.cfg.K\n",
        "\n",
        "        self.pay = nn.ModuleList()\n",
        "        \n",
        "        # Input layer\n",
        "        self.pay.append(nn.Linear(1, num_hidden_nodes))\n",
        "        self.pay.append(nn.LeakyReLU())\n",
        "        \n",
        "        # Hidden layers\n",
        "        for i in range(num_layers - 1):\n",
        "            self.pay.append(nn.Linear(num_hidden_nodes, num_hidden_nodes))\n",
        "            self.pay.append(nn.LeakyReLU())\n",
        "         \n",
        "        # Output layer\n",
        "        self.pay.append(nn.Linear(num_hidden_nodes, 1))\n",
        "        self.pay.append(nn.Sigmoid())\n",
        "        \n",
        "        for m in self.pay:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight.data, gain = nn.init.calculate_gain('leaky_relu'))\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        \n",
        "    def forward(self, v):\n",
        "        out = v[:, None]\n",
        "        for module in self.pay: out = module(out)\n",
        "        return out.flatten()"
      ],
      "id": "5522870a-54bb-40f9-801e-01d1a1a828b8"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "893b54b6-3543-4735-8e71-96981bd25678"
      },
      "outputs": [],
      "source": [
        "def compute_x_interim(pi_interim):\n",
        "    \"\"\"\n",
        "    Computes interim probability of taking the correct action \n",
        "    assuming obedience is satified\n",
        "    \n",
        "    Args:\n",
        "        pi_interim: [Batch_size, Num_States, Num_Signals]\n",
        "    Returns:\n",
        "        x_interim: [Batch_size]\n",
        "    \"\"\"\n",
        "    \n",
        "    return torch.diagonal(pi_interim * theta, offset = 0, dim1 = -2, dim2 = -1).sum(-1)\n",
        "\n",
        "def compute_x_deviation(pi_interim):\n",
        "    \"\"\"\n",
        "    Computes interim probability of taking the correct action \n",
        "    when obedience is not imposed    \n",
        "    Args:\n",
        "        pi_interim: [Batch_size, Num_States, Num_Signals]\n",
        "    Returns:\n",
        "        x_deviation: [Batch_size]\n",
        "    \"\"\"\n",
        "    \n",
        "    return torch.max(pi_interim * theta, axis = -2)[0].sum(-1)\n",
        "\n",
        "\n",
        "def compute_obedience_violations(x_interim, pi_interim):\n",
        "    \"\"\"\n",
        "    Computes obedience violation\n",
        "    Args:\n",
        "        x_inteirm: [Batch]\n",
        "    Returns:\n",
        "        ob_viol: [Batch]\n",
        "    \"\"\"\n",
        "\n",
        "    x_deviation = compute_x_deviation(pi_interim) \n",
        "    ob_viol = F.relu(x_deviation - x_interim)\n",
        "    return ob_viol"
      ],
      "id": "893b54b6-3543-4735-8e71-96981bd25678"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ca06b82e-4bc9-414b-9d72-40449fe5f3c2"
      },
      "outputs": [],
      "source": [
        "def compute_payments_from_fractions(v_i, payoff_interim, i):\n",
        "    \"\"\"\n",
        "    Computes interim payments from pay_frac\n",
        "    Args:\n",
        "        v_i: [Batch]\n",
        "        payoff_interim: [Batch]\n",
        "        pay_frac: [Batch]\n",
        "    Returns:\n",
        "        payment_interim: [Batch]\n",
        "    \"\"\"\n",
        "    \n",
        "    # Compute p_frac\n",
        "    pay_frac = pay_net[i](v_i)\n",
        "    \n",
        "    # Payoff if opting out\n",
        "    payoff_out = max(cfg.theta) - cfg.alpha\n",
        "    \n",
        "    \"\"\" \n",
        "    Pay <= Utility - Utility_out \n",
        "         = v_i * (payoff_interim - pay_out)     \n",
        "    \"\"\"\n",
        "    \n",
        "    payment_interim = v_i * (payoff_interim - payoff_out) * pay_frac\n",
        "    return payment_interim"
      ],
      "id": "ca06b82e-4bc9-414b-9d72-40449fe5f3c2"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "f5151d96-0b8d-4712-93af-1502d7f2d23d"
      },
      "outputs": [],
      "source": [
        "def compute_ir_violation(v_i, payoff_interim, pay_interim):\n",
        "    \"\"\"\n",
        "    Computes IR violation\n",
        "    Args:\n",
        "        v_i: [Batch]\n",
        "        payoff_interim: [Batch]\n",
        "        pay_interim: [Batch]\n",
        "    Returns:\n",
        "        ir_viol: [Batch]\n",
        "    \"\"\"\n",
        "    \n",
        "    # Payoff if opting out\n",
        "    payoff_out = max(cfg.theta) - cfg.alpha    \n",
        "    ir_viol = F.relu( v_i * (payoff_out - payoff_interim) + pay_interim )\n",
        "    return ir_viol"
      ],
      "id": "f5151d96-0b8d-4712-93af-1502d7f2d23d"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "8b93d976-9f4e-4e28-bde8-3edada270d5a"
      },
      "outputs": [],
      "source": [
        "def compute_ic_violation_grid(v_i, payoff_interim, pay_interim):\n",
        "    \"\"\"\n",
        "    Computes IC violation\n",
        "    Args:\n",
        "        v_i: [Batch]\n",
        "        payoff_interim: [Batch]\n",
        "        pay_interim: [Batch]\n",
        "    Returns:\n",
        "        ic_viol: [Batch]\n",
        "        v_mis: [Batch]\n",
        "\n",
        "    Compute v - payoff outer-product and subtract payment\n",
        "    Now we have a utility Mesh u_mesh whose i'th row j'th column has\n",
        "    the value v[i] * payoff[j] - pay[j]. This is exactly the utility of misreporting with b[i] = v[j]\n",
        "    The diagonal is the utility of truthful reporting. (as b[i] = v[i])\n",
        "    Compute ic_violation as max of misreporting - diagonal value.\n",
        "    \n",
        "    We can use this to warm-start GD: To be implemented\n",
        "    \"\"\"\n",
        "\n",
        "    u_mesh = v_i[:, None] * payoff_interim[None, :] - pay_interim[None, :]\n",
        "    \n",
        "    u_true = torch.diag(u_mesh)\n",
        "    u_mis, v_mis_idx =  u_mesh.max(axis = -1)\n",
        "    v_mis = v_i[v_mis_idx]\n",
        "    \n",
        "    ic_viol = F.relu(u_mis - u_true)\n",
        "    return ic_viol, v_mis.detach()"
      ],
      "id": "8b93d976-9f4e-4e28-bde8-3edada270d5a"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "71c0ef64-7a0d-4cae-b56d-a4bfd7f355d9"
      },
      "outputs": [],
      "source": [
        "def compute_misreports_gd(v_i, v_mis_i, v_mesh_i, i, gd_lr = 5e-3, gd_iter = 100):\n",
        "    \n",
        "    # Autograd variables\n",
        "    v_mis_i = v_mis_i.detach().clone()\n",
        "    v_mis_i.requires_grad_(True)\n",
        "    \n",
        "    # Optimizer\n",
        "    opt = torch.optim.Adam([v_mis_i], gd_lr)\n",
        "    \n",
        "    for it in range(gd_iter):\n",
        "        \n",
        "        opt.zero_grad()        \n",
        "        u_mis = torch.zeros(cfg.num_agents).to(device)\n",
        "        \n",
        "        # Compose misreport - v_mesh [NA, BS, NS, NA]\n",
        "        v_mesh_mis = torch.cat((v_mesh_i[:, :, :i], v_mis_i[:, None, None].repeat(1, cfg.num_samples, 1), v_mesh_i[:, :, i + 1:]), axis = -1)\n",
        "        \n",
        "        pi_mesh_mis = pi_net(v_mesh_mis.view(-1, cfg.num_agents)).view(cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)\n",
        "        pi_interim_mis = pi_mesh_mis.mean(axis = -4)\n",
        "\n",
        "        #x_interim: [Batch_size, Num_agents], Probability of taking correct actions\n",
        "        x_interim_all_mis = compute_x_interim(pi_interim_mis) \n",
        "\n",
        "        # payoff_interim: x_i - \\alpha * \\sum_j != i x_j = (1 + \\alpha) x_i - (\\sum_j) x_j\n",
        "        payoff_interim_mis = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all_mis[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all_mis.sum(axis = -1)\n",
        "\n",
        "        # Compute payments\n",
        "        pay_interim_mis = compute_payments_from_fractions(v_mis_i, payoff_interim_mis, i)\n",
        "\n",
        "        u_mis = (v_i * payoff_interim_mis - pay_interim_mis).sum()\n",
        "            \n",
        "        u_mis_loss = (-u_mis.sum())\n",
        "        u_mis_loss.backward(inputs = v_mis_i)\n",
        "        opt.step()        \n",
        "        v_mis_i.data.clamp_(min = 0.0)\n",
        "        \n",
        "        \n",
        "    return v_mis_i.detach().clone()"
      ],
      "id": "71c0ef64-7a0d-4cae-b56d-a4bfd7f355d9"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "77ac7f7d-88b2-4852-b12d-a240d94a4684"
      },
      "outputs": [],
      "source": [
        "def compute_ic_viol(v_i, payoff_interim, pay_interim, v_mis_i, v_mesh_i, i):\n",
        "    \n",
        "    v_mesh_mis = torch.cat((v_mesh_i[:, :, :i], v_mis_i[:, None, None].repeat(1, cfg.num_samples, 1), v_mesh_i[:, :, i + 1:]), axis = -1)\n",
        "    \n",
        "    # Compute interim pi_mis\n",
        "    pi_mesh_mis = pi_net(v_mesh_mis.view(-1, cfg.num_agents)).view(cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)\n",
        "    pi_interim_mis = pi_mesh_mis.mean(axis = -4)\n",
        "    \n",
        "    # Compute x_interim_mis, payoff_interim_mis, pay_interim_mis\n",
        "    x_interim_all_mis = compute_x_interim(pi_interim_mis)\n",
        "    payoff_interim_mis = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all_mis[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all_mis.sum(axis = -1)\n",
        "    pay_interim_mis = compute_payments_from_fractions(v_mis_i, payoff_interim_mis, i)\n",
        "    \n",
        "    # Compute u_mis\n",
        "    u_mis = (v_i * payoff_interim_mis - pay_interim_mis)\n",
        "    \n",
        "    # Compute u_true\n",
        "    u_true = v_i * payoff_interim - pay_interim\n",
        "    \n",
        "    # Compute ic_viol\n",
        "    ic_viol = F.relu(u_mis - u_true)\n",
        "    return ic_viol"
      ],
      "id": "77ac7f7d-88b2-4852-b12d-a240d94a4684"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "a8e2a3e3-6c3e-4759-9169-9b86b3288396"
      },
      "outputs": [],
      "source": [
        "pi_net = PiNet(cfg).to(device)\n",
        "pay_net = [PayNet(cfg).to(device) for _ in range(cfg.num_agents)]\n",
        "# Keep in mind that if the distributions are asymetric, we need two different neural networks"
      ],
      "id": "a8e2a3e3-6c3e-4759-9169-9b86b3288396"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "708c034f-8d53-4fa1-a6bb-c1b6f4afb75d"
      },
      "outputs": [],
      "source": [
        "lag_ob_init = cfg.lag_ob_init\n",
        "lag_ir_init = cfg.lag_ir_init\n",
        "lag_ic_init = cfg.lag_ic_init\n",
        "\n",
        "pho = cfg.pho_init\n",
        "pho_increment = cfg.pho_increment\n",
        "\n",
        "w_ob = torch.ones(cfg.num_agents).to(device) * lag_ob_init\n",
        "w_ir = torch.ones(cfg.num_agents).to(device) * lag_ir_init\n",
        "w_ic = torch.ones(cfg.num_agents).to(device) * lag_ic_init\n",
        "\n",
        "params = []\n",
        "params.extend(list(pi_net.parameters()))\n",
        "for i in range(cfg.num_agents):\n",
        "    params.extend(list(pay_net[i].parameters()))\n",
        "    \n",
        "opt = torch.optim.AdamW(params, lr=cfg.lr)\n",
        "\n",
        "it = 1"
      ],
      "id": "708c034f-8d53-4fa1-a6bb-c1b6f4afb75d"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "27bda925-6cf4-405f-9a11-6411000417f3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "V_sample is a tensor of shape [num_agents, batch_size and num_samples].\n",
        "V_sample[i, :, :] contains 'num_samples' samples of agent i's valuation to be averaged over \n",
        "for the computation of interim values of the remaning agents. These samples are the same \n",
        "for every valuation profile in the minibatch. (i.e V[i, j, :] = V[i, k, :] )\n",
        "\"\"\"\n",
        "V_sample = np.zeros((cfg.num_agents, cfg.batch_size, cfg.num_samples))\n",
        "\n",
        "for i in range(cfg.num_agents):\n",
        "    V_sample[i] = np.tile(samplers(i, cfg.num_samples)[None, :], (cfg.batch_size, 1))"
      ],
      "id": "27bda925-6cf4-405f-9a11-6411000417f3"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "100929ff-9541-4af8-ba94-750010e83e2b",
        "outputId": "c269f37b-c9ad-46c6-d856-0734714bb209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iter: 1000], [Time Elapsed: 101.63s]\n",
            "[Rev: 1.9518], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0032]\n",
            "[Iter: 2000], [Time Elapsed: 204.21s]\n",
            "[Rev: 1.9374], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0008]\n",
            "[Iter: 3000], [Time Elapsed: 306.95s]\n",
            "[Rev: 1.9240], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0008]\n",
            "[Iter: 4000], [Time Elapsed: 409.87s]\n",
            "[Rev: 1.8850], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0008]\n",
            "[Iter: 5000], [Time Elapsed: 512.73s]\n",
            "[Rev: 1.7793], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0005]\n",
            "[Iter: 6000], [Time Elapsed: 615.69s]\n",
            "[Rev: 1.7708], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0004]\n",
            "[Iter: 7000], [Time Elapsed: 718.75s]\n",
            "[Rev: 1.6155], [OB Viol: 0.0001], [IR Viol: 0.0000], [IC Viol: 0.0007]\n",
            "[Iter: 8000], [Time Elapsed: 822.26s]\n",
            "[Rev: 1.8085], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 9000], [Time Elapsed: 926.22s]\n",
            "[Rev: 1.7271], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0003]\n",
            "[Iter: 10000], [Time Elapsed: 1029.95s]\n",
            "[Rev: 1.9684], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0003]\n",
            "[Iter: 11000], [Time Elapsed: 1133.83s]\n",
            "[Rev: 1.8328], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 12000], [Time Elapsed: 1237.69s]\n",
            "[Rev: 1.8226], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 13000], [Time Elapsed: 1341.40s]\n",
            "[Rev: 1.8366], [OB Viol: 0.0001], [IR Viol: 0.0000], [IC Viol: 0.0004]\n",
            "[Iter: 14000], [Time Elapsed: 1445.03s]\n",
            "[Rev: 1.8152], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 15000], [Time Elapsed: 1548.61s]\n",
            "[Rev: 1.7615], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 16000], [Time Elapsed: 1652.10s]\n",
            "[Rev: 1.7967], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 17000], [Time Elapsed: 1755.54s]\n",
            "[Rev: 1.8988], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 18000], [Time Elapsed: 1858.93s]\n",
            "[Rev: 1.9063], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 19000], [Time Elapsed: 1962.39s]\n",
            "[Rev: 1.6310], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 20000], [Time Elapsed: 2065.77s]\n",
            "[Rev: 1.7534], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 21000], [Time Elapsed: 2169.12s]\n",
            "[Rev: 1.5388], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 22000], [Time Elapsed: 2272.42s]\n",
            "[Rev: 1.8919], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 23000], [Time Elapsed: 2375.65s]\n",
            "[Rev: 1.8130], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0002]\n",
            "[Iter: 24000], [Time Elapsed: 2478.93s]\n",
            "[Rev: 1.6596], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 25000], [Time Elapsed: 2582.10s]\n",
            "[Rev: 1.8209], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 26000], [Time Elapsed: 2685.20s]\n",
            "[Rev: 1.8769], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 27000], [Time Elapsed: 2788.39s]\n",
            "[Rev: 1.9871], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0000]\n",
            "[Iter: 28000], [Time Elapsed: 2891.55s]\n",
            "[Rev: 1.7568], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 29000], [Time Elapsed: 2994.65s]\n",
            "[Rev: 1.7225], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Iter: 30000], [Time Elapsed: 3097.75s]\n",
            "[Rev: 2.0054], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "tic = time.time()\n",
        "                                  \n",
        "while it <= cfg.max_iter:\n",
        "    \n",
        "    \n",
        "    opt.zero_grad()\n",
        "    \n",
        "    \"\"\" \n",
        "    Construction of V_mesh:\n",
        "    V_mesh is of shape [num_agents, batch_size, num_samples, num_agents]\n",
        "    What's V_mesh[i, j, k, l]?\n",
        "    V[i, j] - has num_samples elements with the same valuation for agent - i\n",
        "    but with num_samples values from the V_sample array for other agents\n",
        "    \n",
        "    We use this for computation of payment, ic-viol, ob-viol for agent - i only\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    V = np.zeros((cfg.num_agents, cfg.batch_size))\n",
        "    V_mesh = np.zeros((cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents))\n",
        "\n",
        "\n",
        "    for i in range(cfg.num_agents):\n",
        "        V[i] = samplers(i, cfg.batch_size) \n",
        "        for j in range(cfg.num_agents):\n",
        "            if i == j:    \n",
        "                V_mesh[i, :, :, j] = np.tile(V[i][:, None], (1, cfg.num_samples))\n",
        "            else:\n",
        "                V_mesh[i, :, :, j] = V_sample[j]\n",
        "           \n",
        "    v = torch_var(V)\n",
        "    v_mesh = torch_var(V_mesh)\n",
        "    \n",
        "    \n",
        "    pi_mesh = pi_net(v_mesh.view(-1, cfg.num_agents)).view(cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)   \n",
        "    pi_mesh = pi_mesh.mean(axis = -4)\n",
        "        \n",
        "    revenue = torch.zeros(cfg.num_agents).to(device)\n",
        "    ob_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ir_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ic_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(cfg.num_agents):\n",
        "                \n",
        "        #pi_interim: [Batch_size, Num_agents, Num_states, Num_signals], experiments assigned\n",
        "        pi_interim = pi_mesh[i] \n",
        "        \n",
        "        #x_interim: [Batch_size, Num_agents], Probability of taking correct actions\n",
        "        x_interim_all = compute_x_interim(pi_interim) \n",
        "        \n",
        "        # payoff_interim: x_i - \\alpha * \\sum_j != i x_j = (1 + \\alpha) x_i - (\\sum_j) x_j\n",
        "        payoff_interim = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all.sum(axis = -1)\n",
        "        \n",
        "        # Compute payments\n",
        "        pay_interim = compute_payments_from_fractions(v[i], payoff_interim, i)\n",
        "        \n",
        "        # Compute Revenue        \n",
        "        revenue[i] = pay_interim.mean()\n",
        "        \n",
        "        # Compute obedience violations\n",
        "        ob_viol[i] = compute_obedience_violations(x_interim_all[:, i], pi_interim[:, i]).mean()\n",
        "        \n",
        "        # Compute ir violation\n",
        "        ir_viol[i] = compute_ir_violation(v[i], payoff_interim, pay_interim).mean()\n",
        "        \n",
        "        # Compute ic violation: \n",
        "        # Uncomment this for random starts\n",
        "        # v_mis_init = torch_var(samplers(i,cfg.batch_size))\n",
        "        \n",
        "        # Warm-start with the best misreport computed using other minibatch vals\n",
        "        _, v_mis_init = compute_ic_violation_grid(v[i], payoff_interim, pay_interim)\n",
        "                \n",
        "        v_mis = compute_misreports_gd(v[i], v_mis_init, v_mesh[i], i, gd_lr = cfg.gd_lr, gd_iter = cfg.gd_iter)        \n",
        "        ic_viol[i] = compute_ic_viol(v[i], payoff_interim, pay_interim, v_mis, v_mesh[i], i).mean()\n",
        "    \n",
        "\n",
        "    rev_loss = -revenue.sum()\n",
        "    lagrangian = torch.dot(w_ob, ob_viol) + torch.dot(w_ir, ir_viol) + torch.dot(w_ic, ic_viol)\n",
        "    penalty = pho * ((ob_viol**2).sum() + (ir_viol**2).sum() + (ic_viol**2).sum())\n",
        "    \n",
        "    loss = rev_loss + penalty + lagrangian\n",
        "    \n",
        "    loss.backward()   \n",
        "    opt.step()\n",
        "    \n",
        "    if it % cfg.print_iter == 0:\n",
        "        print(\"[Iter: %d], [Time Elapsed: %.2fs]\"%(it, time.time() - tic))\n",
        "        print(\"[Rev: %.4f], [OB Viol: %.4f], [IR Viol: %.4f], [IC Viol: %.4f]\"%(revenue.sum(), ob_viol.mean().item(), ir_viol.mean().item(), ic_viol.mean().item()))\n",
        "        \n",
        "    if it % cfg.lag_up_iter == 0:\n",
        "        w_ob.data += pho * ob_viol.data\n",
        "        w_ic.data += pho * ic_viol.data\n",
        "        \n",
        "    if it % cfg.pho_up_iter == 0:\n",
        "        pho += pho_increment\n",
        "        \n",
        "    it += 1"
      ],
      "id": "100929ff-9541-4af8-ba94-750010e83e2b"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "2c22f1e6-7d2a-49b5-94fa-71802d903559",
        "outputId": "e4f2faef-a5f3-49b6-8398-b2e3f83617e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import scipy.stats\n",
        "D = 81\n",
        "v1 = torch_var(np.linspace(0, 4, D))\n",
        "# v2 = torch_var(np.linspace(0, 0.8, D))\n",
        "s2 = torch_var(np.linspace(0, 8, D))\n",
        "v2 = s2/2\n",
        "v3 = s2.clone()/2\n",
        "v_mesh = torch.stack(torch.meshgrid(v1, v2, indexing = \"ij\"), axis = -1)\n",
        "v_mesh = torch.cat((v_mesh, v_mesh[:,:,1].reshape(D,D,1)),dim=-1)\n",
        "\n",
        "pi_mesh = torch.diagonal(pi_net(v_mesh.view(-1, 3)).view(D, D, cfg.num_agents, cfg.num_states, cfg.num_signals) * theta, 0, -2, -1).sum(-1)\n",
        "AM = numpy_var(pi_mesh)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(ncols = 1, nrows = 1, figsize=(5,4))\n",
        "\n",
        "img_1 = ax.imshow(AM[:, :, 0].transpose(1,0), extent=[0,4,0,8], vmin = 0.0,aspect = 0.5, vmax=1.0, cmap = 'YlOrRd', origin = \"lower\")\n",
        "plt.colorbar(img_1, ax = ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "# img_2 = ax[1].imshow(AM[:, :, 1].transpose(1,0), extent=[0,4,0,8], vmin = 0.0,aspect = 0.5, vmax=1.0, cmap = 'YlOrRd', origin = \"lower\")\n",
        "# plt.colorbar(img_2, ax = ax[1], fraction=0.046, pad=0.04)\n",
        "\n",
        "ax.plot([0, 0.678347], [1.678347, 1.678347], color='black')\n",
        "ax.plot([0.678347, 4],[1.678347, 5],color='black')\n",
        "\n",
        "ax.set_xlabel(\"$v_1$\")\n",
        "ax.set_ylabel(\"$v_{-1}$\")\n",
        "# ax[1].set_xlabel(\"$v_1$\")\n",
        "# ax[1].set_ylabel(\"$v_{-1}$\")\n",
        "\n",
        "fig.text(0.5, 1, r\"Irr, $\\alpha=%.2f, \\theta=%.2f$\"%(cfg.alpha, max(cfg.theta)), ha='center', size = 16)\n",
        "fig.tight_layout()"
      ],
      "id": "2c22f1e6-7d2a-49b5-94fa-71802d903559"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ccc0787-619e-48e7-9ed6-846a834043b6"
      },
      "outputs": [],
      "source": [
        "V = np.linspace(0, 8, 801)\n",
        "V_mesh = np.stack(np.meshgrid(V, V, indexing = \"ij\"), axis = -1)\n",
        "\n",
        "def compute_VV(v):\n",
        "    vv = np.zeros(v.shape)\n",
        "    for i in range(v.shape[0]):\n",
        "        if(v[i] <= (7.0 - np.sqrt(5.0))/2.0):\n",
        "            vv[i] = 2.0 * v[i] - 4.0\n",
        "        elif(v[i] <= (11.0 - np.sqrt(5.0))/2.0):\n",
        "            vv[i] = 3.0 - np.sqrt(5.0)\n",
        "        else:\n",
        "            vv[i] = 2.0 * v[i] - 8.0\n",
        "    return(vv)\n",
        "\n",
        "VV = compute_VV(V)\n",
        "VV_mesh = np.stack(np.meshgrid(VV, VV, indexing = \"ij\"), axis = -1)"
      ],
      "id": "2ccc0787-619e-48e7-9ed6-846a834043b6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b927338-96b3-4e94-95c0-083210d30a82"
      },
      "outputs": [],
      "source": [
        "def compute_alloc(V_mesh, VV_mesh):\n",
        "    x = np.zeros(VV_mesh.shape)\n",
        "    rev = 0.0\n",
        "    for i in range(VV_mesh.shape[0]):\n",
        "        for j in range(VV_mesh.shape[1]):\n",
        "            x[i, j, 0] =  VV_mesh[i, j, 0] > cfg.alpha * VV_mesh[i, j, 1]\n",
        "            x[i, j, 1] =  VV_mesh[i, j, 1] > cfg.alpha * VV_mesh[i, j, 0]\n",
        "            if V_mesh[i, j, 0] <= 2 and V_mesh[i, j, 1] <= 2:\n",
        "               x[i, j, 0] = 1.0\n",
        "               x[i, j, 1] = 1.0\n",
        "            \n",
        "        rev += x[i, j, 0] * (VV_mesh[i, j, 0] - cfg.alpha * VV_mesh[i, j, 1])\n",
        "    return x, rev/(VV_mesh.shape[0] * VV_mesh.shape[1])"
      ],
      "id": "4b927338-96b3-4e94-95c0-083210d30a82"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "592197c8-f26a-41c8-9b1b-e2a012cd2eb0"
      },
      "outputs": [],
      "source": [
        "X, rev = compute_alloc(V_mesh, VV_mesh)\n",
        "print(np.shape(X))"
      ],
      "id": "592197c8-f26a-41c8-9b1b-e2a012cd2eb0"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iCJE-4A6x-TO",
        "outputId": "0f15d649-2538-4c09-afb1-aa6bf67d0ded"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e97590cc-a152-486d-a5af-8ba3b9fae47b\", \"new3p_exp_theta_0.50_alpha_2.00.pth\", 337535)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_31a25ec3-9d27-49d8-848e-07ccd22bf937\", \"new3p_exp_theta_0.50_alpha_2.00p1.pth\", 327059)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a3af9c28-6273-4595-81bf-1f6b963065be\", \"new3p_exp_theta_0.50_alpha_2.00p2.pth\", 327059)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "torch.save(pi_net.state_dict(), 'new3p_exp_theta_0.50_alpha_2.00.pth')\n",
        "torch.save(pay_net[0].state_dict(), 'new3p_exp_theta_0.50_alpha_2.00p1.pth')\n",
        "torch.save(pay_net[1].state_dict(), 'new3p_exp_theta_0.50_alpha_2.00p2.pth')\n",
        "# # # download checkpoint file\n",
        "files.download('new3p_exp_theta_0.50_alpha_2.00.pth')\n",
        "files.download('new3p_exp_theta_0.50_alpha_2.00p1.pth')\n",
        "files.download('new3p_exp_theta_0.50_alpha_2.00p2.pth')\n",
        "# files.upload()\n",
        "# state_dict = torch.load('3p_exp_theta_0.50_alpha_2.00.pth')\n",
        "# state_dict_2 = torch.load('3p_exp_theta_0.50_alpha_0.50p1.pth')\n",
        "# state_dict_3 = torch.load('3p_exp_theta_0.50_alpha_0.50p2.pth')\n",
        "# pi_net.load_state_dict(state_dict)\n",
        "# pay_net[0].load_state_dict(state_dict_2)\n",
        "# pay_net[1].load_state_dict(state_dict_3)"
      ],
      "id": "iCJE-4A6x-TO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8104df4-bb98-40a7-83d2-6539aa0e8625"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X[:, :,0].T, origin = \"lower\")"
      ],
      "id": "a8104df4-bb98-40a7-83d2-6539aa0e8625"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b25b1a1-91fa-42cc-a5ad-3e0074345a90"
      },
      "outputs": [],
      "source": [
        "rev"
      ],
      "id": "0b25b1a1-91fa-42cc-a5ad-3e0074345a90"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cc45f8d-2565-4c4a-8ba0-1f000df6251c"
      },
      "outputs": [],
      "source": [
        "X.min()"
      ],
      "id": "7cc45f8d-2565-4c4a-8ba0-1f000df6251c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "232a0050-b215-483c-be6c-dbf0fa73d682"
      },
      "outputs": [],
      "source": [
        "U1 = (VV_mesh[:, :, 0] - 0.5 * VV_mesh[:, :, 1])\n",
        "U2 = (VV_mesh[:201, :201, 0] - 0.5 * VV_mesh[:201, :201, 1])"
      ],
      "id": "232a0050-b215-483c-be6c-dbf0fa73d682"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90a177c2-f1cb-4907-bd32-2930195d2752"
      },
      "outputs": [],
      "source": [
        "X = (U1 > 0)"
      ],
      "id": "90a177c2-f1cb-4907-bd32-2930195d2752"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "138f167e-dfc2-4380-a8ae-8d8ff598d4c8"
      },
      "outputs": [],
      "source": [
        "X[:201, :201] = 1.0"
      ],
      "id": "138f167e-dfc2-4380-a8ae-8d8ff598d4c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "821da283-7851-45ba-9906-b02899e8985e"
      },
      "outputs": [],
      "source": [
        "VV_mesh.shape"
      ],
      "id": "821da283-7851-45ba-9906-b02899e8985e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17037346-43cf-41fb-b33e-92a78b0a3aac"
      },
      "outputs": [],
      "source": [
        "(X * (VV_mesh[:, :, 0] - 0.5 * VV_mesh[:, :, 1])).mean()"
      ],
      "id": "17037346-43cf-41fb-b33e-92a78b0a3aac"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "84aa220f-a73f-40ed-9066-59a44231abe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241565f9-5e36-459c-f487-b1210085ceaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Rev: 1.8188], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.8225], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.8226], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.8222], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n",
            "[Rev: 1.8209], [OB Viol: 0.0000], [IR Viol: 0.0000], [IC Viol: 0.0001]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import gc\n",
        "tic = time.time()\n",
        "                              \n",
        "\n",
        "\"\"\" \n",
        "Construction of V_mesh:\n",
        "V_mesh is of shape [num_agents, batch_size, num_samples, num_agents]\n",
        "What's V_mesh[i, j, k, l]?\n",
        "V[i, j] - has num_samples elements with the same valuation for agent - i\n",
        "but with num_samples values from the V_sample array for other agents\n",
        "\n",
        "We use this for computation of payment, ic-viol, ob-viol for agent - i only\n",
        "\"\"\"\n",
        "ctrrev = 0\n",
        "ctrob = 0\n",
        "ctrir = 0\n",
        "ctric = 0\n",
        "testitr = 5000\n",
        "for iters in range(testitr):\n",
        "    opt.zero_grad()\n",
        "  \n",
        "    \"\"\" \n",
        "    Construction of V_mesh:\n",
        "    V_mesh is of shape [num_agents, batch_size, num_samples, num_agents]\n",
        "    What's V_mesh[i, j, k, l]?\n",
        "    V[i, j] - has num_samples elements with the same valuation for agent - i\n",
        "    but with num_samples values from the V_sample array for other agents\n",
        "    \n",
        "    We use this for computation of payment, ic-viol, ob-viol for agent - i only\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    V = np.zeros((cfg.num_agents, cfg.batch_size))\n",
        "    V_mesh = np.zeros((cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents))\n",
        "\n",
        "\n",
        "    for i in range(cfg.num_agents):\n",
        "        V[i] = samplers(i, cfg.batch_size)    \n",
        "        for j in range(cfg.num_agents):\n",
        "            if i == j:    \n",
        "                V_mesh[i, :, :, j] = np.tile(V[i][:, None], (1, cfg.num_samples))\n",
        "            else:\n",
        "                V_mesh[i, :, :, j] = V_sample[j]\n",
        "          \n",
        "    v = torch_var(V)\n",
        "    v_mesh = torch_var(V_mesh)\n",
        "    \n",
        "    \n",
        "    pi_mesh = pi_net(v_mesh.view(-1, cfg.num_agents)).view(cfg.num_agents, cfg.batch_size, cfg.num_samples, cfg.num_agents, cfg.num_states, cfg.num_signals)   \n",
        "    pi_mesh = pi_mesh.mean(axis = -4)\n",
        "        \n",
        "    revenue = torch.zeros(cfg.num_agents).to(device)\n",
        "    ob_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ir_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    ic_viol = torch.zeros(cfg.num_agents).to(device)\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(cfg.num_agents):\n",
        "                \n",
        "        #pi_interim: [Batch_size, Num_agents, Num_states, Num_signals], experiments assigned\n",
        "        pi_interim = pi_mesh[i] \n",
        "        \n",
        "        #x_interim: [Batch_size, Num_agents], Probability of taking correct actions\n",
        "        x_interim_all = compute_x_interim(pi_interim) \n",
        "        \n",
        "        # payoff_interim: x_i - \\alpha * \\sum_j != i x_j = (1 + \\alpha) x_i - (\\sum_j) x_j\n",
        "        payoff_interim = (1 + cfg.alpha/(cfg.num_agents-1)) * x_interim_all[:, i] - cfg.alpha/(cfg.num_agents-1) * x_interim_all.sum(axis = -1)\n",
        "        \n",
        "        # Compute payments\n",
        "        pay_interim = compute_payments_from_fractions(v[i], payoff_interim, i)\n",
        "        \n",
        "        # Compute Revenue        \n",
        "        revenue[i] = pay_interim.mean()\n",
        "        \n",
        "        # Compute obedience violations\n",
        "        ob_viol[i] = compute_obedience_violations(x_interim_all[:, i], pi_interim[:, i]).mean()\n",
        "        \n",
        "        # Compute ir violation\n",
        "        ir_viol[i] = compute_ir_violation(v[i], payoff_interim, pay_interim).mean()\n",
        "        \n",
        "        # Compute ic violation: \n",
        "        # Uncomment this for random starts\n",
        "        # v_mis_init = torch_var(samplers[i](cfg.batch_size))\n",
        "        \n",
        "        # Warm-start with the best misreport computed using other minibatch vals\n",
        "        _, v_mis_init = compute_ic_violation_grid(v[i], payoff_interim, pay_interim)\n",
        "                \n",
        "        v_mis = compute_misreports_gd(v[i], v_mis_init, v_mesh[i], i, gd_lr = cfg.gd_lr, gd_iter = cfg.gd_iter)        \n",
        "        ic_viol[i] = compute_ic_viol(v[i], payoff_interim, pay_interim, v_mis, v_mesh[i], i).mean()\n",
        "    \n",
        "\n",
        "    rev_loss = -revenue.sum()\n",
        "    lagrangian = torch.dot(w_ob, ob_viol) + torch.dot(w_ir, ir_viol) + torch.dot(w_ic, ic_viol)\n",
        "    penalty = pho * ((ob_viol**2).sum() + (ir_viol**2).sum() + (ic_viol**2).sum())\n",
        "    \n",
        "    loss = rev_loss + penalty + lagrangian\n",
        "    if it % cfg.lag_up_iter == 0:\n",
        "        w_ob.data += pho * ob_viol.data\n",
        "        w_ic.data += pho * ic_viol.data\n",
        "        \n",
        "    if it % cfg.pho_up_iter == 0:\n",
        "        pho += pho_increment\n",
        "        \n",
        "    it += 1\n",
        "\n",
        "    ctrrev += revenue.sum()\n",
        "    ctrob += ob_viol.mean().item()\n",
        "    ctrir += ir_viol.mean().item()\n",
        "    ctric += ic_viol.mean().item()\n",
        "    loss.backward()\n",
        "    if iters % 1000 == 0 and iters != 0:\n",
        "      print(\"[Rev: %.4f], [OB Viol: %.4f], [IR Viol: %.4f], [IC Viol: %.4f]\"%(ctrrev/iters, ctrob/iters, ctrir/iters, ctric/iters))\n",
        "\n",
        "print(\"[Rev: %.4f], [OB Viol: %.4f], [IR Viol: %.4f], [IC Viol: %.4f]\"%(ctrrev/testitr, ctrob/testitr, ctrir/testitr, ctric/testitr))\n"
      ],
      "id": "84aa220f-a73f-40ed-9066-59a44231abe0"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python [conda env:.conda-data_markets]",
      "language": "python",
      "name": "conda-env-.conda-data_markets-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}